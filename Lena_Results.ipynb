{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class result:\n",
    "    def __init__(self, ID, authors, year, journal, title, abstract, keywords, decision, no, pNo, yes, pYes, note, path):\n",
    "        self.ID = ID\n",
    "        self.authors = str(authors)\n",
    "        self.year = year\n",
    "        self.journal = str(journal)\n",
    "        self.title = str(title)\n",
    "        self.abstract = str(abstract)\n",
    "        self.keywords = str(keywords)\n",
    "        self.decision =decision\n",
    "        self.no = str(no)\n",
    "        if(self.no =='nan'):\n",
    "            self.no=\"\"\n",
    "        self.pNo = str(pNo)\n",
    "        if(self.pNo =='nan'):\n",
    "            self.pNo=\"\"\n",
    "            \n",
    "        self.yes = str(yes)\n",
    "        if(self.yes =='nan'):\n",
    "            self.yes=\"\"\n",
    "            \n",
    "        self.pYes = str(pYes)\n",
    "        if(self.pYes =='nan'):\n",
    "            self.pYes=\"\"\n",
    "            \n",
    "        self.note = str(note)\n",
    "        if(self.note =='nan'):\n",
    "            self.note=\"\"\n",
    "        self.path = str(path)\n",
    "        \n",
    "paths = glob.glob(\"*.csv\")##saving all screening results as instances of result\n",
    "refList = []\n",
    "for path in paths:\n",
    "    train = pd.read_csv(path); #change it into your file name if it is in other names\n",
    "    for i in range(len(train['ID'])):\n",
    "        #j = str(result['Journal'])\n",
    "        refList.append(result(train.loc[i][0], train.loc[i][1],train.loc[i][2],train.loc[i][3],train.loc[i][4],train.loc[i][5],train.loc[i][6],train.loc[i][7],train.loc[i][8],train.loc[i][9],train.loc[i][10],train.loc[i][11],train.loc[i][12], path))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTo():#for writing back to an excel spreadsheet\n",
    "    if(result.ID not in file['ID']): \n",
    "        file['ID'].append(result.ID)\n",
    "        file['Authors'].append(result.authors)\n",
    "        file['Year'].append(result.year)\n",
    "        file['Journal'].append(result.journal)\n",
    "        file['Title'].append(result.title)\n",
    "        file['Abstract'].append(result.abstract)\n",
    "        file['Keywords'].append(result.keywords)\n",
    "        file['Decision'].append(result.decision)\n",
    "        file['Terms for No'].append(result.no)\n",
    "        file['Terms for P No'].append(result.pNo) \n",
    "        file['Terms for P Yes'].append(result.pYes)  \n",
    "        file['Terms for YES'].append(result.yes) \n",
    "        file['Extra note'].append(result.note) \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(a,b):\n",
    "    \n",
    "    if (a ==\"\" and b!=\"\"):\n",
    "        return b\n",
    "    elif(a !=\"\" and b==\"\"):\n",
    "        return a\n",
    "    elif(a ==\"\" and b==\"\"):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return a +\", \"+b\n",
    "\n",
    "def duplicates():#de-duplication\n",
    "    if result.decision==-2 and compare.decision==-1:\n",
    "        result.decision = -1\n",
    "        result.note = \"*Merged to -1. \" + concat(result.note,compare.note)\n",
    "    elif result.decision==-1 and compare.decision==-2:\n",
    "        result.decision = -1\n",
    "        result.note = \"*Merged to -1. \" + concat(result.note,compare.note)\n",
    "    elif result.decision==2 and compare.decision==1:\n",
    "        result.decision = 1\n",
    "        result.note = \"*Merged to 1. \" + concat(result.note,compare.note)\n",
    "    elif result.decision==1 and compare.decision==2:\n",
    "        result.decision = 1\n",
    "        result.note = \"*Merged to 1. \" + concat(result.note,compare.note)\n",
    "        \n",
    "    elif result.decision == compare.decision:\n",
    "        \n",
    "        result.note = \"*Merged, no conflict. \" + concat(result.note,compare.note)\n",
    "    elif result.decision != compare.decision:\n",
    "        result.note = \"*Judgement needed. (\"+str(result.decision)+str(compare.decision)+\") \" + concat(result.note,compare.note)\n",
    "    else:\n",
    "        print('no decision found' + str(result.decision) + ' and '+str(compare.decision))\n",
    "    \n",
    "    \n",
    "    result.yes = concat(result.yes,compare.yes)\n",
    "    result.no = concat(result.no,compare.no)\n",
    "    result.pYes = concat(result.pYes,compare.pYes)\n",
    "    result.pNo = concat(result.pNo,compare.pNo)\n",
    "    \n",
    "###############contradictions in reviewer decisions\n",
    "d = {'ID': [], 'Path 1': [], 'Decision 1': [], 'Decision 2': [], 'Path 2': [],  'Abstract':[]}\n",
    "file = {'ID': [],'Authors': [],'Year': [],'Journal': [],'Title': [],'Abstract': [], 'Keywords': [],'Decision': [],'Terms for No': [],'Terms for P No': [],'Terms for P Yes': [],\n",
    "        'Terms for YES': [],'Extra note': [],}\n",
    "\n",
    "\n",
    "for result in refList:#for each screening result\n",
    "    \n",
    "    for compare in refList:#for each screening result: going through the list again, to compair elements pairwise\n",
    "        if (result.ID == compare.ID) and (result.path != compare.path):#pairwise comparison found matching IDs with a different result(not with itself since path is different)\n",
    "            #print('Id a = %s, IDb = %s'%(result.path, compare.path))\n",
    "            \n",
    "            \n",
    "            \n",
    "            if result.decision != compare.decision:#we only care if the decisions are different in those 2 results. Otherwise, data is written back to the master file\n",
    "                if(result.ID not in d['ID']):\n",
    "                    #############df to display results\n",
    "                    d['ID'].append(result.ID)\n",
    "                    d['Path 1'].append(result.path)\n",
    "                    d['Path 2'].append(compare.path)\n",
    "                    d['Decision 1'].append(result.decision)\n",
    "                    d['Decision 2'].append(compare.decision)\n",
    "                    d['Abstract'].append(result.abstract)\n",
    "                    #delete both disagreeing results\n",
    "                    #assimilate the close results and make them 1\n",
    "                    #add the revised results\n",
    "            duplicates()        \n",
    "    writeTo() \n",
    "                \n",
    "        \n",
    "    \n",
    "                    \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDict(dict1, line):\n",
    "    words =re.split(r'[;,\\r\\n]', line)\n",
    "    for w in words:\n",
    "        w= re.sub(r'\\*', '', w)#removing unwanted differences\n",
    "        w=w.lower().strip()    \n",
    "        if (w != '' and w !=\"nan\"):#exclude those\n",
    "            \n",
    "            dict1.get(w)#removing unwanted differences\n",
    "            dict1[w] = dict1.get(w, 0) + 1#the dict that counts occurrences by field\n",
    "            \n",
    "            if (w in dict_all): #increment counting variable\n",
    "                dict_all[w][0] += 1\n",
    "        \n",
    "            else: #make entry vector\n",
    "                dict_all[w] = [1,0,0, 0, 0]\n",
    "            if(result.decision == 2):\n",
    "                dict_all[w][1] += 1#yes\n",
    "            elif(result.decision == 1): \n",
    "                dict_all[w][2] += 1#pyes\n",
    "            elif(result.decision == -1):\n",
    "                dict_all[w][3] += 1#pno\n",
    "            elif(result.decision == -2):\n",
    "                dict_all[w][4] += 1#no\n",
    "            else:\n",
    "                print('error ' + str(result.decision))\n",
    "\n",
    "def addKeywords(line):\n",
    "    words = re.split(r'[;,\\r\\n]', line)#####keeps the wildcard stars\n",
    "    for w in words:\n",
    "        w=w.lower().strip()\n",
    "        if (w != '' and w !=\"nan\"):\n",
    "            if (w in dict_keywords): #increment counting variable\n",
    "                dict_keywords[w][0] += 1\n",
    "        \n",
    "            else: #make entry vector\n",
    "                dict_keywords[w] = [1,0,0, 0, 0]\n",
    "            if(result.decision == 2):\n",
    "                dict_keywords[w][1] += 1#yes\n",
    "            elif(result.decision == 1): \n",
    "                dict_keywords[w][2] += 1#pyes\n",
    "            elif(result.decision == -1):\n",
    "                dict_keywords[w][3] += 1#pno\n",
    "            elif(result.decision == -2):\n",
    "                dict_keywords[w][4] += 1#no\n",
    "            #else:\n",
    "                #print('error ' + str(result.decision))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n",
      "error nan\n"
     ]
    }
   ],
   "source": [
    "###########de-ducplicating the terms givien by reviewers and making dicts for excel file\n",
    "\n",
    "dict_no = {}\n",
    "dict_Pno = {}\n",
    "dict_Pyes = {}\n",
    "dict_yes = {}\n",
    "dict_all = {}\n",
    "\n",
    "for result in refList:##for custom terms\n",
    "    \n",
    "    addDict(dict_yes, result.yes)\n",
    "    addDict(dict_no, result.no)\n",
    "    addDict(dict_Pno, result.pNo)\n",
    "    addDict(dict_Pyes, result.pYes)\n",
    "    \n",
    "words = {'Word': [], 'Total': [], 'Yes': [], 'P yes': [], 'P no': [],  'No':[]}#for excel\n",
    "for key,value in dict_all.items():\n",
    "    words['Word'].append(key)\n",
    "    words['Total'].append(dict_all[key][0])\n",
    "    words['Yes'].append(dict_all[key][1])\n",
    "    words['P yes'].append(dict_all[key][2])\n",
    "    words['P no'].append(dict_all[key][3])\n",
    "    words['No'].append(dict_all[key][4]) \n",
    "    \n",
    "dict_keywords = {}\n",
    "for result in refList:\n",
    "    addKeywords(result.keywords)\n",
    "keywords = {'Word': [], 'Total': [], 'Yes': [], 'P yes': [], 'P no': [],  'No':[]}#for excel\n",
    "for key,value in dict_keywords.items():\n",
    "    keywords['Word'].append(key)\n",
    "    keywords['Total'].append(dict_keywords[key][0])\n",
    "    keywords['Yes'].append(dict_keywords[key][1])\n",
    "    keywords['P yes'].append(dict_keywords[key][2])\n",
    "    keywords['P no'].append(dict_keywords[key][3])\n",
    "    keywords['No'].append(dict_keywords[key][4])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "{'natural language processing': 13, 'word embeddings': 2, 'automated content analysis': 2, 'quality indicators': 2, 'networks validation': 2, 'markov logic network': 2, 'causal association rules': 2, 'decision tree': 4, 'connectedness testing': 2, 'disconnected network': 2, 'graph theory': 2, 'indirect comparison': 2, 'network meta-analysis': 2, 'big data': 5, 'statistical analysis': 2, 'infoepidemiology': 2, 'infographics': 2, 'pattern recognition': 4, 'systematic reviews': 4, 'common data models': 2, 'cdm': 2, 'data harmonisation': 2, 'data reuse': 2, 'data transformation': 2, 'feature extraction': 2, 'meta-analysis': 9, 'reproducibility': 2, 'research methodologies': 2, 'automated text classification': 3, 'systematic review': 6, 'decision trees algorithm': 3, 'bibliographic databases': 2, 'information science': 2, 'data accuracy': 2, 'data collection': 2, 'screening': 5, 'study design': 3, 'automation of systematic reviews': 3, 'systematic reviews as topic': 2, 'data interpretation': 1, 'vocabulary': 4, 'automation': 4, 'dictionary': 1, 'dictionaries': 1, 'machine learning': 7, 'extract': 1, 'extracting': 1, 'machine learning based predictive models': 1, 'automated meta-analysis': 3, 'neurosynth': 3, 'sentiment analysis techniques': 3, 'automated maintenance of review-aggregation websites': 3, 'supervised machine learning/classification': 3, 'semantic orientation': 3, 'data mining': 12, 'process mining': 3, 'text mining': 9, 'human reviewer': 3, 'python code scripts': 3, 'text mining algorithm': 3, 'data mining/statistics & numerical data': 3, 'data mining/history/methods': 3, 'deep learning': 3, 'extraction': 3, 'machine learning techniques. convolutional neural networks': 3, 'data analytics techniques': 3, 'systematically mined': 3, 'data mining approach': 3, 'automated approaches': 3, 'automated method': 3, 'heuristic approach': 3, 'text-mining': 3, 'automated methods': 3, 'automated and semi-automated methods': 3, 'algorithms': 3, 'electronic health records (ehrs)': 3, 'robotreviewer': 3, 'risk of bias': 3, 'computed': 3, 'reliability': 3, 'data mining/methods': 3, 'bayesian methods': 3, 'network meta-analysis (nma)': 3, 'visualizing': 3, 'source software singularity-python': 3, 'pico-based title-only screening': 3, 'computer-aided': 3, 'term completeness': 3, 'extracting understanding from clinical text': 3, 'new approaches to evidence synthesis': 3, 'consistency of trial registration': 3, 'search term development': 3, 'automated text data mining': 5, 'identify and collate the type of academic literature being published using national health surveys': 2, 'monthly-automated database searches': 2, 'systematic mapping': 3, 'abstract screening workload': 3, 'study identification': 5, 'evidence map': 3, 'insufficient information to judge how relevant': 2, 'automatic assessment': 3, 'umls': 3, 'search strategies': 3, 'automated summarization': 2, 'semantic relations': 1, 'big data technologies': 1, 'rapidminer': 1, 'iteration': 1, 'structured data': 1, 'machine-supported expert review': 1, 'computer-aided techniques': 1, 'innovative technologies': 1, 'detect inconsistency': 1, 'node-splitting': 1, 'nlp': 2, 'missed terms': 1, 'mismapped concepts': 1, 'mappings of concepts': 1, 'data corpus': 1, 'thematic analysis': 1, 'bibliometric ranking': 1, 'google scholar citation profiles': 1, 'snowball method': 1, 'related papers': 1, 'snowballing': 1, 'domain analysis': 1, 'informatics tools': 1, 'data-driven algorithms': 1, 'algorithm': 1, 'data mining techniques': 1, 'manual review': 1, 'semantic concept recognition software': 1, 'leximancer': 1, 'stochastic computing': 1, 'to probabilistic-based pattern-recognition analysis': 1, 'semantic synonyms': 1, 'mining': 1, 'recognition-based methods': 1, 'semantic framework': 1, 'co-word network': 1, 'co-citation network': 1, 'automatic evidence retrieval': 1, 'detection of outliers': 1, 'informatics': 1, 'extracting structured information': 1, 'metamap': 1, 'innovative methods': 1, 'visual analytics': 1, 'hard-to-detect evidence': 1, 'knowledge representation': 1, 'data mining algorithms': 1, 'classification': 1, 'automated search of key words': 1, 'data processing on aggregate results': 1, 'methodological developments in searching': 1, 'medical nlp': 1, 'word frequency analysis': 1, 'published health quality improvement documents': 1, 'taxonomy development': 1, 'automated network meta-analytic approach': 1, 'temporal reasoning': 1, 'artifical intelligence': 1, 'event detection': 1, 'support vector machine': 1, 'data-mining': 1, 'classifier': 1, 'living review': 1}\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_yes.keys()))\n",
    "print(dict_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appear in yes AND Pno {'information science', 'automated content analysis', 'quality indicators', 'markov logic network', 'algorithm', 'data mining', 'algorithms', 'bibliographic databases'}\n",
      "Appear in yes AND no {'big data', 'statistical analysis', 'automation', 'network meta-analysis', 'common data models', 'systematic review', 'feature extraction', 'data reuse', 'natural language processing'}\n",
      "Appear in no AND Pyes {'artificial intelligence', 'decision support systems'}\n"
     ]
    }
   ],
   "source": [
    "#############ambivalent terms\n",
    "set_no = set(dict_no.keys())\n",
    "\n",
    "\n",
    "set_Pno = set(dict_Pno.keys())\n",
    "set_Pyes = set(dict_Pyes.keys())\n",
    "set_yes = set(dict_yes.keys())\n",
    "\n",
    "no_Pno = set_no.intersection(set_Pno)#common members between no and pno\n",
    "set_Pno = set_Pno-no_Pno#deleting the common members from pno, since they are already in no\n",
    "\n",
    "yes_Pyes = set_yes.intersection(set_Pyes)#same for yes\n",
    "set_Pyes = set_Pyes - yes_Pyes\n",
    "\n",
    "\n",
    "yes_Pno = set_yes.intersection(set_Pno)\n",
    "print(\"Appear in yes AND Pno \"+ str(yes_Pno))\n",
    "yes_no = set_yes.intersection(set_no)\n",
    "print(\"Appear in yes AND no \"+str(yes_no))\n",
    "no_Pyes = set_no.intersection(set_Pyes)\n",
    "print(\"Appear in no AND Pyes \"+str(no_Pyes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Journal of clinical epidemiology': [24, 9, 4, 1, 10], 'PloS one': [166, 4, 9, 27, 124], 'Journal of the American Medical Informatics Association : JAMIA': [126, 6, 9, 18, 93], 'BMC medical research methodology': [14, 0, 2, 3, 9], 'PLoS medicine': [7, 0, 0, 2, 5], 'Artificial intelligence in medicine': [57, 1, 2, 15, 39], 'Systematic reviews': [47, 15, 9, 9, 14], 'Journal of medical Internet research': [64, 2, 0, 13, 48], 'Research synthesis methods': [37, 6, 13, 8, 9], 'Studies in health technology and informatics': [151, 5, 15, 31, 99], 'International journal of medical informatics': [74, 1, 4, 13, 56], 'BMC health services research': [15, 0, 0, 3, 12], 'BMC bioinformatics': [51, 2, 4, 7, 38], 'International journal of technology assessment in health care': [5, 0, 0, 0, 4], 'Journal of machine learning research : JMLR': [2, 2, 0, 0, 0]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Total</th>\n",
       "      <th>Yes</th>\n",
       "      <th>P yes</th>\n",
       "      <th>P no</th>\n",
       "      <th>No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Journal of clinical epidemiology</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PloS one</td>\n",
       "      <td>166</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Journal of the American Medical Informatics As...</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMC medical research methodology</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLoS medicine</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial intelligence in medicine</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Systematic reviews</td>\n",
       "      <td>47</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Journal of medical Internet research</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Research synthesis methods</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Studies in health technology and informatics</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International journal of medical informatics</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BMC health services research</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BMC bioinformatics</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>International journal of technology assessment...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Journal of machine learning research : JMLR</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  Total  Yes  P yes  \\\n",
       "0                    Journal of clinical epidemiology     24    9      4   \n",
       "1                                            PloS one    166    4      9   \n",
       "2   Journal of the American Medical Informatics As...    126    6      9   \n",
       "3                    BMC medical research methodology     14    0      2   \n",
       "4                                       PLoS medicine      7    0      0   \n",
       "5                 Artificial intelligence in medicine     57    1      2   \n",
       "6                                  Systematic reviews     47   15      9   \n",
       "7                Journal of medical Internet research     64    2      0   \n",
       "8                          Research synthesis methods     37    6     13   \n",
       "9        Studies in health technology and informatics    151    5     15   \n",
       "10       International journal of medical informatics     74    1      4   \n",
       "11                       BMC health services research     15    0      0   \n",
       "12                                 BMC bioinformatics     51    2      4   \n",
       "13  International journal of technology assessment...      5    0      0   \n",
       "14        Journal of machine learning research : JMLR      2    2      0   \n",
       "\n",
       "    P no   No  \n",
       "0      1   10  \n",
       "1     27  124  \n",
       "2     18   93  \n",
       "3      3    9  \n",
       "4      2    5  \n",
       "5     15   39  \n",
       "6      9   14  \n",
       "7     13   48  \n",
       "8      8    9  \n",
       "9     31   99  \n",
       "10    13   56  \n",
       "11     3   12  \n",
       "12     7   38  \n",
       "13     0    4  \n",
       "14     0    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############Relationship between journal and rating\n",
    "journals = {}\n",
    "\n",
    "#print(len(refList))\n",
    "for result in refList:\n",
    "    #print(result.journal)\n",
    "    if (result.journal in journals): #increment counting variable\n",
    "        journals[result.journal][0] += 1\n",
    "        \n",
    "    else: #make entry vector\n",
    "        journals[result.journal] = [1,0,0,0,0]\n",
    "    if(result.decision == 2):\n",
    "        journals[result.journal][1] += 1#yes\n",
    "    elif(result.decision == 1): \n",
    "        journals[result.journal][2] += 1#pyes\n",
    "    elif(result.decision == -1):\n",
    "        journals[result.journal][3] += 1#pno\n",
    "    elif(result.decision == -2):\n",
    "        journals[result.journal][4] += 1#no\n",
    "    #else:\n",
    "        #print('error ' + str(result.decision))\n",
    "        \n",
    "j = {'Name': [], 'Total': [], 'Yes': [], 'P yes': [], 'P no': [],  'No':[]}\n",
    "for key,value in journals.items():\n",
    "    j['Name'].append(key)\n",
    "    j['Total'].append(journals[key][0])\n",
    "    j['Yes'].append(journals[key][1])\n",
    "    j['P yes'].append(journals[key][2])\n",
    "    j['P no'].append(journals[key][3])\n",
    "    j['No'].append(journals[key][4])\n",
    "\n",
    "print(journals)    \n",
    "df_journal = pd.DataFrame(data=j)\n",
    "\n",
    "df_journal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2018: [167, 14, 14, 60, 79], 2019: [2, 2, 0, 0, 0], 2011: [32, 2, 1, 8, 21], 2012: [34, 1, 2, 3, 28], 2013: [52, 3, 9, 1, 39], 2010: [32, 4, 2, 5, 21], 2009: [24, 2, 7, 2, 13], 2008: [23, 0, 0, 3, 20], 2007: [21, 0, 2, 0, 19], 2006: [14, 0, 2, 0, 12], 2001: [5, 0, 0, 2, 3], 2000: [7, 0, 0, 2, 5], 1999: [10, 0, 1, 4, 5], 1998: [10, 0, 0, 1, 9], 1997: [14, 0, 2, 0, 12], 1996: [3, 0, 0, 1, 2], 1995: [2, 0, 0, 0, 2], 1994: [6, 0, 0, 0, 6], 1993: [4, 0, 0, 2, 2], 2017: [175, 2, 12, 30, 131], 2016: [78, 7, 8, 6, 55], 2015: [57, 10, 6, 9, 29], 2014: [68, 6, 3, 11, 47]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Total</th>\n",
       "      <th>Yes</th>\n",
       "      <th>P yes</th>\n",
       "      <th>P no</th>\n",
       "      <th>No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>167</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1999</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1997</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1996</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1994</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Total  Yes  P yes  P no   No\n",
       "0   2018    167   14     14    60   79\n",
       "1   2019      2    2      0     0    0\n",
       "2   2011     32    2      1     8   21\n",
       "3   2012     34    1      2     3   28\n",
       "4   2013     52    3      9     1   39\n",
       "5   2010     32    4      2     5   21\n",
       "6   2009     24    2      7     2   13\n",
       "7   2008     23    0      0     3   20\n",
       "8   2007     21    0      2     0   19\n",
       "9   2006     14    0      2     0   12\n",
       "10  2001      5    0      0     2    3\n",
       "11  2000      7    0      0     2    5\n",
       "12  1999     10    0      1     4    5\n",
       "13  1998     10    0      0     1    9\n",
       "14  1997     14    0      2     0   12\n",
       "15  1996      3    0      0     1    2\n",
       "16  1995      2    0      0     0    2\n",
       "17  1994      6    0      0     0    6\n",
       "18  1993      4    0      0     2    2\n",
       "19  2017    175    2     12    30  131\n",
       "20  2016     78    7      8     6   55\n",
       "21  2015     57   10      6     9   29\n",
       "22  2014     68    6      3    11   47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########relationship between year and rating\n",
    "\n",
    "years = {}\n",
    "#print(len(refList))\n",
    "for result in refList:\n",
    "    #print(result.journal)\n",
    "    if (result.year in years): #increment counting variable\n",
    "        years[result.year][0] += 1\n",
    "        \n",
    "    else: #make entry vector\n",
    "        years[result.year] = [1,0,0,0,0]\n",
    "    if(result.decision == 2):\n",
    "        years[result.year][1] += 1#yes\n",
    "    elif(result.decision == 1): \n",
    "        years[result.year][2] += 1#pyes\n",
    "    elif(result.decision == -1):\n",
    "        years[result.year][3] += 1#pno\n",
    "    elif(result.decision == -2):\n",
    "        years[result.year][4] += 1#no\n",
    "    #else:\n",
    "        #print('error ' + str(result.decision))\n",
    "        \n",
    "y = {'Year': [], 'Total': [], 'Yes': [], 'P yes': [], 'P no': [],  'No':[]}\n",
    "for key,value in years.items():\n",
    "    y['Year'].append(key)\n",
    "    y['Total'].append(years[key][0])\n",
    "    y['Yes'].append(years[key][1])\n",
    "    y['P yes'].append(years[key][2])\n",
    "    y['P no'].append(years[key][3])\n",
    "    y['No'].append(years[key][4])        \n",
    "\n",
    "print(years)    \n",
    "df_years = pd.DataFrame(data=y)\n",
    "\n",
    "df_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "differenceFrame = pd.DataFrame(data=d)\n",
    "masterFrame = pd.DataFrame(data=file)\n",
    "journalFrame = pd.DataFrame(data=j)\n",
    "yearFrame = pd.DataFrame(data=y)\n",
    "wordsFrame = pd.DataFrame(data=words)\n",
    "keywordsFrame = pd.DataFrame(data=keywords)\n",
    "writer = pd.ExcelWriter('AutoSession2_results.xlsx', engine='xlsxwriter')\n",
    "differenceFrame.to_excel(writer, sheet_name= 'Differences')\n",
    "masterFrame.to_excel(writer, sheet_name= 'All')\n",
    "journalFrame.to_excel(writer, sheet_name= 'Journal data')\n",
    "yearFrame.to_excel(writer, sheet_name= 'Year data')\n",
    "wordsFrame.to_excel(writer, sheet_name= 'Terms data')\n",
    "keywordsFrame.to_excel(writer, sheet_name='Keywords data')\n",
    "writer.save()               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
