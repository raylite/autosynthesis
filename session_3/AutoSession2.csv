ID,Authors,Year,Journal,Title,Abstract,Keywords,Decision,Terms for NO,Terms for P No,Terms for P Yes,Terms for YES,Extra note
151,Cocos,2017,Journal of the American Medical Informatics Association : JAMIA,Deep learning for pharmacovigilance: recurrent neural network architectures for labeling adverse drug reactions in Twitter posts,"Objective: Social media is an important pharmacovigilance data source for adverse drug reaction (ADR) identification. Human review of social media data is infeasible due to data quantity, thus natural language processing techniques are necessary. Social media includes informal vocabulary and irregular grammar, which challenge natural language processing methods. Our objective is to develop a scalable, deep-learning approach that exceeds state-of-the-art ADR detection performance in social media. Materials and Methods: We developed a recurrent neural network (RNN) model that labels words in an input sequence with ADR membership tags. The only input features are word-embedding vectors, which can be formed through task-independent pretraining or during ADR detection training. Results: Our best-performing RNN model used pretrained word embeddings created from a large, non-domain-specific Twitter dataset. It achieved an approximate match F-measure of 0.755 for ADR identification on the dataset, compared to 0.631 for a baseline lexicon system and 0.65 for the state-of-the-art conditional random field model. Feature analysis indicated that semantic information in pretrained word embeddings boosted sensitivity and, combined with contextual awareness captured in the RNN, precision. Discussion: Our model required no task-specific feature engineering, suggesting generalizability to additional sequence-labeling tasks. Learning curve analysis showed that our model reached optimal performance with fewer training examples than the other models. Conclusion: ADR detection performance in social media is significantly improved by using a contextually aware model and word embeddings formed from large, unlabeled datasets. The approach reduces manual data-labeling requirements and is scalable to large social media datasets.", Drug-Related Side Effects and Adverse Reactions/*diagnosis; Humans; Machine Learning; *Natural Language Processing; *Neural Networks (Computer); *Pharmacovigilance; *Social Media; Twitter messaging; adverse drug reaction; natural language processing; neural networks (computer); social media,-1,,Twitter,,,
152,Cahan,2017,Journal of medical Internet research,A Learning Health Care System Using Computer-Aided Diagnosis,"Physicians intuitively apply pattern recognition when evaluating a patient. Rational diagnosis making requires that clinical patterns be put in the context of disease prior probability, yet physicians often exhibit flawed probabilistic reasoning. Difficulties in making a diagnosis are reflected in the high rates of deadly and costly diagnostic errors. Introduced 6 decades ago, computerized diagnosis support systems are still not widely used by internists. These systems cannot efficiently recognize patterns and are unable to consider the base rate of potential diagnoses. We review the limitations of current computer-aided diagnosis support systems. We then portray future diagnosis support systems and provide a conceptual framework for their development. We argue for capturing physician knowledge using a novel knowledge representation model of the clinical picture. This model (based on structured patient presentation patterns) holds not only symptoms and signs but also their temporal and semantic interrelations. We call for the collection of crowdsourced, automatically deidentified, structured patient patterns as means to support distributed knowledge accumulation and maintenance. In this approach, each structured patient pattern adds to a self-growing and -maintaining knowledge base, sharing the experience of physicians worldwide. Besides supporting diagnosis by relating the symptoms and signs with the final diagnosis recorded, the collective pattern map can also provide disease base-rate estimates and real-time surveillance for early detection of outbreaks. We explain how health care in resource-limited settings can benefit from using this approach and how it can be applied to provide feedback-rich medical education for both students and practitioners."," Delivery of Health Care/*methods; Diagnosis, Computer-Assisted/*methods; Humans; *crowdsourcing; *decision support systems, clinical; *diagnosis support systems; *diagnosis, computer-assisted; *diagnostic errors; *knowledge bases; *knowledge management; *pattern recognition, automated; *structured knowledge representation",-2,Computer-aided diagnosis,,,,
153,Cotton,2017,BMC bioinformatics,flippant-An R package for the automated analysis of fluorescence-based scramblase assays,"BACKGROUND: The lipid scrambling activity of protein extracts and purified scramblases is typically measured using a fluorescence-based assay. While the assay has yielded insight into the scramblase activity in crude membrane preparations, functional validation of candidate scramblases, stoichiometry of scramblase complexes as well as ATP-dependence of flippases, data analysis in its context has remained a task involving many manual steps. RESULTS: With the extension package ""flippant"" to R, a free software environment for statistical computing and graphics, we introduce an integrated solution for the analysis and publication-grade graphical presentation of dithionite scramblase assays and demonstrate its utility in revisiting an originally manual analysis from the publication record, closely reproducing the reported results. CONCLUSIONS: ""flippant"" allows for quick, reproducible data analysis of scramblase activity assays and provides a platform for review, dissemination and extension of the strategies it employs.", Biochemistry/*methods; Fluorescence; Humans; *Lipids; Phospholipid Transfer Proteins/analysis/*metabolism; *Software; Dithionite scramblase assay; R; Scramblase,-2,,,,,
154,Souri,2017,Systematic reviews,Identification of validated case definitions for chronic disease using electronic medical records: a systematic review protocol,"BACKGROUND: Primary care electronic medical record (EMR) data are being used for research, surveillance, and clinical monitoring. To broaden the reach and usability of EMR data, case definitions must be specified to identify and characterize important chronic conditions. The purpose of this study is to identify all case definitions for a set of chronic conditions that have been tested and validated in primary care EMR and EMR-linked data. This work will provide a reference list of case definitions, together with their performance metrics, and will identify gaps where new case definitions are needed. METHODS: We will consider a set of 40 chronic conditions, previously identified as potentially important for surveillance in a review of multimorbidity measures. We will perform a systematic search of the published literature to identify studies that describe case definitions for clinical conditions in EMR data and report the performance of these definitions. We will stratify our search by studies that use EMR data alone and those that use EMR-linked data. We will compare the performance of different definitions for the same conditions and explore the influence of data source, jurisdiction, and patient population. DISCUSSION: EMR data from primary care providers can be compiled and used for benefit by the healthcare system. Not only does this work have the potential to further develop disease surveillance and health knowledge, EMR surveillance systems can provide rapid feedback to participating physicians regarding their patients. Existing case definitions will serve as a starting point for the development and validation of new case definitions and will enable better surveillance, research, and practice feedback based on detailed clinical EMR data. SYSTEMATIC REVIEW REGISTRATION: PROSPERO CRD42016040020.", Chronic Disease/*epidemiology; *Electronic Health Records/statistics & numerical data; Humans; Reproducibility of Results; *Systematic Reviews as Topic; *Big data; *Case definitions; *Chronic disease; *Electronic medical record; *Systematic review,-2,,Electronic medical records,,,
155,Wang,2017,PloS one,Clinical evaluation of new automatic coronary-specific best cardiac phase selection algorithm for single-beat coronary CT angiography,"The aim of this study was to evaluate the workflow efficiency of a new automatic coronary-specific reconstruction technique (Smart Phase, GE Healthcare-SP) for selection of the best cardiac phase with least coronary motion when compared with expert manual selection (MS) of best phase in patients with high heart rate. A total of 46 patients with heart rates above 75 bpm who underwent single beat coronary computed tomography angiography (CCTA) were enrolled in this study. CCTA of all subjects were performed on a 256-detector row CT scanner (Revolution CT, GE Healthcare, Waukesha, Wisconsin, US). With the SP technique, the acquired phase range was automatically searched in 2% phase intervals during the reconstruction process to determine the optimal phase for coronary assessment, while for routine expert MS, reconstructions were performed at 5% intervals and a best phase was manually determined. The reconstruction and review times were recorded to measure the workflow efficiency for each method. Two reviewers subjectively assessed image quality for each coronary artery in the MS and SP reconstruction volumes using a 4-point grading scale. The average HR of the enrolled patients was 91.1+/-19.0bpm. A total of 204 vessels were assessed. The subjective image quality using SP was comparable to that of the MS, 1.45+/-0.85 vs 1.43+/-0.81 respectively (p = 0.88). The average time was 246 seconds for the manual best phase selection, and 98 seconds for the SP selection, resulting in average time saving of 148 seconds (60%) with use of the SP algorithm. The coronary specific automatic cardiac best phase selection technique (Smart Phase) improves clinical workflow in high heart rate patients and provides image quality comparable with manual cardiac best phase selection. Reconstruction of single-beat CCTA exams with SP can benefit the users with less experienced in CCTA image interpretation."," Adult; Aged; Algorithms; Computed Tomography Angiography/*methods; Coronary Angiography/*methods; Coronary Artery Disease/*diagnostic imaging; Coronary Vessels/*diagnostic imaging; Female; Heart Rate; Humans; Male; Middle Aged; Radiographic Image Enhancement/*methods; Radiographic Image Interpretation, Computer-Assisted/*methods",-2,,,,,
156,Tusting,2017,PLoS medicine,Housing Improvements and Malaria Risk in Sub-Saharan Africa: A Multi-Country Analysis of Survey Data,"BACKGROUND: Improvements to housing may contribute to malaria control and elimination by reducing house entry by malaria vectors and thus exposure to biting. We tested the hypothesis that the odds of malaria infection are lower in modern, improved housing compared to traditional housing in sub-Saharan Africa (SSA). METHODS AND FINDINGS: We analysed 15 Demographic and Health Surveys (DHS) and 14 Malaria Indicator Surveys (MIS) conducted in 21 countries in SSA between 2008 and 2015 that measured malaria infection by microscopy or rapid diagnostic test (RDT). DHS/MIS surveys record whether houses are built with finished materials (e.g., metal) or rudimentary materials (e.g., thatch). This information was used to develop a binary housing quality variable where houses built using finished wall, roof, and floor materials were classified as ""modern"", and all other houses were classified as ""traditional"". Conditional logistic regression was used to determine the association between housing quality and prevalence of malaria infection in children aged 0-5 y, adjusting for age, gender, insecticide-treated net (ITN) use, indoor residual spraying, household wealth, and geographic cluster. Individual survey odds ratios (ORs) were combined to determine a summary OR using a random effects meta-analysis. Of 284,532 total children surveyed, 139,318 were tested for malaria infection using microscopy (n = 131,652) or RDT (n = 138,540). Within individual surveys, malaria prevalence measured by microscopy ranged from 0.4% (Madagascar 2011) to 45.5% (Burkina Faso 2010) among children living in modern houses and from 0.4% (The Gambia 2013) to 70.6% (Burkina Faso 2010) in traditional houses, and malaria prevalence measured by RDT ranged from 0.3% (Senegal 2013-2014) to 61.2% (Burkina Faso 2010) in modern houses and from 1.5% (The Gambia 2013) to 79.8% (Burkina Faso 2010) in traditional houses. Across all surveys, modern housing was associated with a 9% to 14% reduction in the odds of malaria infection (microscopy: adjusted OR 0.91, 95% CI 0.85-0.97, p = 0.003; RDT: adjusted OR 0.86, 95% CI 0.80-0.92, p < 0.001). This association was consistent regardless of ITN usage. As a comparison, the odds of malaria infection were 15% to 16% lower among ITN users versus non-users (microscopy: adjusted OR 0.84, 95% CI 0.79-0.90, p < 0.001; RDT: adjusted OR 0.85, 95% CI 0.80-0.90, p < 0.001). The main limitation of this study is that residual confounding by household wealth of the observed association between housing quality and malaria prevalence is possible, since the wealth index may not have fully captured differences in socioeconomic position; however, the use of multiple national surveys offers the advantage of a large sample size and the elimination of many biases typically associated with pooling observational data. CONCLUSIONS: Housing quality is an important risk factor for malaria infection across the spectrum of malaria endemicity in SSA, with a strength of association between housing quality and malaria similar to that observed between ITN use and malaria. Improved housing should be considered a promising intervention for malaria control and elimination and long-term prevention of reintroduction."," Africa South of the Sahara/epidemiology; Child, Preschool; Cross-Sectional Studies; Female; *Housing/standards; Humans; Infant; Infant, Newborn; Malaria/*epidemiology; Male; Risk Factors",-2,,,,,
157,Marshall,2017,Systematic reviews,Documenting research with transgender and gender diverse people: protocol for an evidence map and thematic analysis,"BACKGROUND: There is limited information about how transgender, gender diverse, and Two-Spirit (trans) people have been represented and studied by researchers. The objectives of this study are to (1) map and describe trans research in the social sciences, sciences, humanities, health, education, and business, (2) identify evidence gaps and opportunities for more responsible research with trans people, (3) assess the use of text mining for study identification, and (4) increase access to trans research for key stakeholders through the creation of a web-based evidence map. METHODS: Study design was informed by community consultations and pilot searches. Eligibility criteria were established to include all original research of any design, including trans people or their health information, and published in English in peer-reviewed journals. A complex electronic search strategy based on relevant concepts in 15 databases was developed to obtain a broad range of results linked to transgender, gender diverse, and Two-Spirit individuals and communities. Searches conducted in early 2015 resulted in 25,242 references after removal of duplicates. Based on the number of references, resources, and an objective to capture upwards of 90% of the existing literature, this study is a good candidate for text mining using Latent Dirichlet Allocation to improve efficiency of the screening process. The following information will be collected for evidence mapping: study topic, study design, methods and data sources, recruitment strategies, sample size, sample demographics, researcher name and affiliation, country where research was conducted, funding source, and year of publication. DISCUSSION: The proposed research incorporates an extensive search strategy, text mining, and evidence map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text.", Documentation/*methods; Humans; *Research Design; *Sexual and Gender Minorities; Transgender Persons; *Evidence map; *Gender diverse; *Research ethics; *Research prioritization; *Responsible research; *Text mining; *Transgender,2,,,Evidence map,,
158,Rochefort,2017,BMC health services research,Accuracy and generalizability of using automated methods for identifying adverse events from electronic health record data: a validation study protocol,"BACKGROUND: Adverse events (AEs) in acute care hospitals are frequent and associated with significant morbidity, mortality, and costs. Measuring AEs is necessary for quality improvement and benchmarking purposes, but current detection methods lack in accuracy, efficiency, and generalizability. The growing availability of electronic health records (EHR) and the development of natural language processing techniques for encoding narrative data offer an opportunity to develop potentially better methods. The purpose of this study is to determine the accuracy and generalizability of using automated methods for detecting three high-incidence and high-impact AEs from EHR data: a) hospital-acquired pneumonia, b) ventilator-associated event and, c) central line-associated bloodstream infection. METHODS: This validation study will be conducted among medical, surgical and ICU patients admitted between 2013 and 2016 to the Centre hospitalier universitaire de Sherbrooke (CHUS) and the McGill University Health Centre (MUHC), which has both French and English sites. A random 60% sample of CHUS patients will be used for model development purposes (cohort 1, development set). Using a random sample of these patients, a reference standard assessment of their medical chart will be performed. Multivariate logistic regression and the area under the curve (AUC) will be employed to iteratively develop and optimize three automated AE detection models (i.e., one per AE of interest) using EHR data from the CHUS. These models will then be validated on a random sample of the remaining 40% of CHUS patients (cohort 1, internal validation set) using chart review to assess accuracy. The most accurate models developed and validated at the CHUS will then be applied to EHR data from a random sample of patients admitted to the MUHC French site (cohort 2) and English site (cohort 3)-a critical requirement given the use of narrative data -, and accuracy will be assessed using chart review. Generalizability will be determined by comparing AUCs from cohorts 2 and 3 to those from cohort 1. DISCUSSION: This study will likely produce more accurate and efficient measures of AEs. These measures could be used to assess the incidence rates of AEs, evaluate the success of preventive interventions, or benchmark performance across hospitals."," Catheterization, Central Venous/*adverse effects; Cross Infection/*epidemiology; Electronic Health Records/statistics & numerical data; Female; Hospitalization/statistics & numerical data; Hospitals; Humans; Incidence; Male; Natural Language Processing; Pneumonia/epidemiology; Quality Improvement; Respiration, Artificial/*adverse effects; *Acute care hospital; *Adverse events; *Automated detection; *Data warehouse; *Electronic health record; *Natural language processing; *Patient safety",-1,,Electronic health record ,,,
159,Liu,2017,PloS one,The association between body mass index and mortality among Asian peritoneal dialysis patients: A meta-analysis,"BACKGROUND: Previous studies have revealed that increased body mass index (BMI) is associated with decreased mortality among hemodialysis patients. However, few studies have dealt with the association between BMI and mortality among patients undergoing peritoneal dialysis (PD) and even fewer studies have focused on the Asian PD patients. The reported studies were often non-conclusive and some even yielded contradictory results. This paper, to our best knowledge, registers the first attempt to systematically review the current literature and summarize new results on the association between BMI and mortality among the Asian PD population. METHOD: A systematic literature review was performed in Medline and EMBASE to identify relevant cohort studies on all-cause and cardiovascular disease (CVD) mortality stratified by BMI categories tailored to Asians among the Asian PD population. We meta-analyzed individual results based on a random effect model, strictly complying with Preferred Reporting Items for Systematic Reviews and Meta-analysis. RESULTS: The paper reviews seven cohort studies with a total of 3,610 Asian PD patients. Obese group (BMI = 25-29.9 kg/m2) was associated with higher risk of all-cause mortality (HR = 1.46, 95%CI [1.07-1.98]; p = 0.02) and CVD mortality (HR = 2.01, 95%CI [1.14-3.54]; p = 0.02), compared to the normal group (BMI = 18.5-22.9 kg/m2). The underweight group (BMI<18.5kg/m2) was also associated with an elevated risk of all-cause mortality (HR = 2.11, 95%CI [1.46-3.07]; p<0.001). No significant associations between BMI with all-cause mortality were found among the overweight group (23-24.9 kg/m2) (HR = 1.00, 95%CI [0.76-1.32]; p = 0.9). The association between BMI and CVD mortality risk among the underweight and overweight groups was found nonsignificant (p = 0.5 and 0.6 respectively). CONCLUSION: Obesity is associated with increased mortality in Asian PD patients. The study indicates a ""V-shaped"" trend in the association between BMI and mortality in these patients.", *Body Mass Index; Humans; Obesity/*physiopathology; Peritoneal Dialysis/*mortality; Risk Factors; Survival Rate,-2,,,,,
160,Cahan,2017,International journal of medical informatics,Computer-aided assessment of the generalizability of clinical trial results,"BACKGROUND: The effects of an intervention on patients from populations other than that included in a trial may vary as a result of differences in population features, treatment administration, or general setting. Determining the generalizability of a trial to a target population is important in clinical decision making at both the individual practitioner and policy-making levels. However, awareness to the challenges associated with the assessment of generalizability of trials is low and tools to facilitate such assessment are lacking. METHODS: We review the main factors affecting the generalizability of a clinical trial results beyond the trial population. We then propose a framework for a standardized evaluation of parameters relevant to determining the external validity of clinical trials to produce a ""generalizability score"". We then apply this framework to populations of patients with heart failure included in trials, cohorts and registries to demonstrate the use of the generalizability score and its graphic representation along three dimensions: participants' demographics, their clinical profile and intervention setting. We use the generalizability score to compare a single trial to multiple ""target"" clinical scenarios. Additionally, we present the generalizability score of several studies with regard to a single ""target"" population. RESULTS: Similarity indices vary considerably between trials and target population, but inconsistent reporting of participant characteristics limit head-to-head comparisons. CONCLUSION: We discuss the challenges involved in performing automatic assessment of trial generalizability at scale and propose the adoption of a standard format for reporting the characteristics of trial participants to enable better interpretation of their results.", Clinical Trials as Topic/*standards/*statistics & numerical data; *Computer-Aided Design; Humans; *Patient Selection; *Research Design; *Clinical trials; *Decision support; *External validity; *Generalizability; *Similarity assessment,-1,,,Automatic assessment ,,
161,Abbott,2017,Journal of the American Medical Informatics Association : JAMIA,Automatic health record review to help prioritize gravely ill Social Security disability applicants,"Objective: Every year, thousands of patients die waiting for disability benefits from the Social Security Administration. Some qualify for expedited service under the Compassionate Allowance (CAL) initiative, but CAL software focuses exclusively on information from a single form field. This paper describes the development of a supplemental process for identifying some overlooked but gravely ill applicants, through automatic annotation of health records accompanying new claims. We explore improved prioritization instead of fully autonomous claims approval. Materials and Methods: We developed a sample of claims containing medical records at the moment of arrival in a single office. A series of tools annotated both patient records and public Web page descriptions of CAL medical conditions. We trained random forests to identify CAL patients and validated each model with 10-fold cross validation. Results: Our main model, a general CAL classifier, had an area under the receiver operating characteristic curve of 0.915. Combining this classifier with existing software improved sensitivity from 0.960 to 0.994, detecting every deceased patient, but reducing positive predictive value to 0.216. Discussion: True positive CAL identification is a priority, given CAL patient mortality. Mere prioritization of the false positives would not create a meaningful burden in terms of manual review. Death certificate data suggest the presence of truly ill patients among putative false positives. Conclusion: To a limited extent, it is possible to identify gravely ill Social Security disability applicants by analyzing annotations of unstructured electronic health records, and the level of identification is sufficient to be useful in prioritizing case reviews."," *Critical Illness; Decision Trees; *Disability Evaluation; *Disabled Persons; *Electronic Health Records; Eligibility Determination/*methods; Humans; Information Storage and Retrieval/methods; Insurance, Disability; *Natural Language Processing; ROC Curve; *Social Security; United States; Social Security; disability; government; health records; natural language processing",-2,,Health records ,,,
162,Tsai,2017,PloS one,Serum Uric Acid and Progression of Kidney Disease: A Longitudinal Analysis and Mini-Review,"BACKGROUND: Increasing evidence supports the association between hyperuricemia and incident chronic kidney disease (CKD); however, there are conflicting data regarding the role of hyperuricemia in the progression of CKD. This study retrospectively assessed the longitudinal association between uric acid (UA) level and CKD progression in a Chinese population lived in Taiwan. METHODS: Patients with physician diagnosis of hyperuricemia or receiving urate-lowering therapy between 2003 and 2005 were identified in the electronic medical records (EMR) of a tertiary medical center and were followed up until December 31, 2011. Patients were divided into four UA categories at the cut-off 6, 8, and 10 mg/dL. CKD progression was estimated by the change of estimated glomerular filtration rate (eGFR) in the linear mixed models. Kidney failure was defined as an eGFR less than 15 mL/min/1.73 m2 or requiring renal replacement therapy. RESULTS: A total of 739 patients were analyzed. In the full-adjusted model, patients with a baseline UA level >/=6 mg/dL had greater decline in eGFR ((beta = -9.6, 95% CI -16.1, -3.1), comparing to those with a UA level less than 6 mg/dL. When stratifying patients into four UA categories, all three hyperuricemia categories (UA6-8, 8-10, >/=10 mg/dL) associated with a greater decline in eGFR over the follow-up period with an increasing dose-response, comparing to the lowest UA category. The risk of progression to renal failure increased 7% (hazard ratio 1.07, 95% CI 1.00, 1.14) for each 1mg/dL increase in baseline UA level. The influences of hyperuricemia on eGFR decline and the risk of kidney failure were more prominent in patients without proteinuria than those with proteinuria. CONCLUSION: Our study showed a higher uric acid level is associated with a significant rapid decline in eGFR and a higher risk of kidney failure, particularly in patients without proteinuria. Our findings suggest hyperuricemia is a potential modifiable factor of CKD progression.", Cohort Studies; Disease Progression; Humans; Kidney Diseases/blood/*pathology; Longitudinal Studies; Retrospective Studies; Uric Acid/*blood,-2,,,,,
163,Schiff,2017,Journal of the American Medical Informatics Association : JAMIA,Screening for medication errors using an outlier detection system,"Objective: The study objective was to evaluate the accuracy, validity, and clinical usefulness of medication error alerts generated by an alerting system using outlier detection screening. Materials and Methods: Five years of clinical data were extracted from an electronic health record system for 747 985 patients who had at least one visit during 2012-2013 at practices affiliated with 2 academic medical centers. Data were screened using the system to detect outliers suggestive of potential medication errors. A sample of 300 charts was selected for review from the 15 693 alerts generated. A coding system was developed and codes assigned based on chart review to reflect the accuracy, validity, and clinical value of the alerts. Results: Three-quarters of the chart-reviewed alerts generated by the screening system were found to be valid in which potential medication errors were identified. Of these valid alerts, the majority (75.0%) were found to be clinically useful in flagging potential medication errors or issues. Discussion: A clinical decision support (CDS) system that used a probabilistic, machine-learning approach based on statistically derived outliers to detect medication errors generated potentially useful alerts with a modest rate of false positives. The performance of such a surveillance and alerting system is critically dependent on the quality and completeness of the underlying data. Conclusion: The screening system was able to generate alerts that might otherwise be missed with existing CDS systems and did so with a reasonably high degree of alert usefulness when subjected to review of patients' clinical contexts and details."," *Decision Support Systems, Clinical; Humans; Machine Learning; *Medical Order Entry Systems; Medication Errors/*prevention & control; Outpatient Clinics, Hospital; *clinical decision support; *electronic health records; *machine learning; *medication alert systems; *patient safety",-2,,,,,
164,Gu,2017,International journal of medical informatics,Visualizing the knowledge structure and evolution of big data research in healthcare informatics,"BACKGROUND: In recent years, the literature associated with healthcare big data has grown rapidly, but few studies have used bibliometrics and a visualization approach to conduct deep mining and reveal a panorama of the healthcare big data field. METHODS: To explore the foundational knowledge and research hotspots of big data research in the field of healthcare informatics, this study conducted a series of bibliometric analyses on the related literature, including papers' production trends in the field and the trend of each paper's co-author number, the distribution of core institutions and countries, the core literature distribution, the related information of prolific authors and innovation paths in the field, a keyword co-occurrence analysis, and research hotspots and trends for the future. RESULTS: By conducting a literature content analysis and structure analysis, we found the following: (a) In the early stage, researchers from the United States, the People's Republic of China, the United Kingdom, and Germany made the most contributions to the literature associated with healthcare big data research and the innovation path in this field. (b) The innovation path in healthcare big data consists of three stages: the disease early detection, diagnosis, treatment, and prognosis phase, the life and health promotion phase, and the nursing phase. (c) Research hotspots are mainly concentrated in three dimensions: the disease dimension (e.g., epidemiology, breast cancer, obesity, and diabetes), the technical dimension (e.g., data mining and machine learning), and the health service dimension (e.g., customized service and elderly nursing). CONCLUSION: This study will provide scholars in the healthcare informatics community with panoramic knowledge of healthcare big data research, as well as research hotspots and future research directions.", Bibliometrics; *Biomedical Research; Data Mining/*methods; *Databases as Topic; Humans; *Medical Informatics; *Bibliometrics; *Big data; *Healthcare informatics; *Knowledge management; *Knowledge structure,-1,,,,,
165,Maenner,2016,PloS one,Development of a Machine Learning Algorithm for the Surveillance of Autism Spectrum Disorder,"The Autism and Developmental Disabilities Monitoring (ADDM) Network conducts population-based surveillance of autism spectrum disorder (ASD) among 8-year old children in multiple US sites. To classify ASD, trained clinicians review developmental evaluations collected from multiple health and education sources to determine whether the child meets the ASD surveillance case criteria. The number of evaluations collected has dramatically increased since the year 2000, challenging the resources and timeliness of the surveillance system. We developed and evaluated a machine learning approach to classify case status in ADDM using words and phrases contained in children's developmental evaluations. We trained a random forest classifier using data from the 2008 Georgia ADDM site which included 1,162 children with 5,396 evaluations (601 children met ADDM ASD criteria using standard ADDM methods). The classifier used the words and phrases from the evaluations to predict ASD case status. We evaluated its performance on the 2010 Georgia ADDM surveillance data (1,450 children with 9,811 evaluations; 754 children met ADDM ASD criteria). We also estimated ASD prevalence using predictions from the classification algorithm. Overall, the machine learning approach predicted ASD case statuses that were 86.5% concordant with the clinician-determined case statuses (84.0% sensitivity, 89.4% predictive value positive). The area under the resulting receiver-operating characteristic curve was 0.932. Algorithm-derived ASD ""prevalence"" was 1.46% compared to the published (clinician-determined) estimate of 1.55%. Using only the text contained in developmental evaluations, a machine learning algorithm was able to discriminate between children that do and do not meet ASD surveillance criteria at one surveillance site.", *Algorithms; Area Under Curve; Autism Spectrum Disorder/classification/*diagnosis; Child; Female; Georgia/epidemiology; Humans; *Machine Learning; Male; Prevalence; ROC Curve; Sensitivity and Specificity,-1,,,,,
166,Kal,2016,PloS one,Is Implicit Motor Learning Preserved after Stroke? A Systematic Review with Meta-Analysis,"Many stroke patients experience difficulty with performing dual-tasks. A promising intervention to target this issue is implicit motor learning, as it should enhance patients' automaticity of movement. Yet, although it is often thought that implicit motor learning is preserved post-stroke, evidence for this claim has not been systematically analysed yet. Therefore, we systematically reviewed whether implicit motor learning is preserved post-stroke, and whether patients benefit more from implicit than from explicit motor learning. We comprehensively searched conventional (MEDLINE, Cochrane, Embase, PEDro, PsycINFO) and grey literature databases (BIOSIS, Web of Science, OpenGrey, British Library, trial registries) for relevant reports. Two independent reviewers screened reports, extracted data, and performed a risk of bias assessment. Overall, we included 20 out of the 2177 identified reports that allow for a succinct evaluation of implicit motor learning. Of these, only 1 study investigated learning on a relatively complex, whole-body (balance board) task. All 19 other studies concerned variants of the serial-reaction time paradigm, with most of these focusing on learning with the unaffected hand (N = 13) rather than the affected hand or both hands (both: N = 4). Four of the 20 studies compared explicit and implicit motor learning post-stroke. Meta-analyses suggest that patients with stroke can learn implicitly with their unaffected side (mean difference (MD) = 69 ms, 95% CI[45.1, 92.9], p < .00001), but not with their affected side (standardized MD = -.11, 95% CI[-.45, .25], p = .56). Finally, implicit motor learning seemed equally effective as explicit motor learning post-stroke (SMD = -.54, 95% CI[-1.37, .29], p = .20). However, overall, the high risk of bias, small samples, and limited clinical relevance of most studies make it impossible to draw reliable conclusions regarding the effect of implicit motor learning strategies post-stroke. High quality studies with larger samples are warranted to test implicit motor learning in clinically relevant contexts.", Aged; Humans; Learning/*physiology; Middle Aged; Motor Skills/*physiology; Reaction Time; Recovery of Function; Stroke/*physiopathology/psychology; Stroke Rehabilitation,-2,,,,,
167,Canela-Xandri,2016,PloS one,Improved Genetic Profiling of Anthropometric Traits Using a Big Data Approach,"Genome-wide association studies (GWAS) promised to translate their findings into clinically beneficial improvements of patient management by tailoring disease management to the individual through the prediction of disease risk. However, the ability to translate genetic findings from GWAS into predictive tools that are of clinical utility and which may inform clinical practice has, so far, been encouraging but limited. Here we propose to use a more powerful statistical approach, the use of which has traditionally been limited due to computational requirements and lack of sufficiently large individual level genotyped cohorts, but which improve the prediction of multiple medically relevant phenotypes using the same panel of SNPs. As a proof of principle, we used a shared panel of 319,038 common SNPs with MAF > 0.05 to train the prediction models in 114,264 unrelated White-British individuals for height and four obesity related traits (body mass index, basal metabolic rate, body fat percentage, and waist-to-hip ratio). We obtained prediction accuracies that ranged between 46% and 75% of the maximum achievable given the captured heritable component. For height, this represents an improvement in prediction accuracy of up to 68% (184% more phenotypic variance explained) over SNPs reported to be robustly associated with height in a previous GWAS meta-analysis of similar size. Across-population predictions in White non-British individuals were similar to those in White-British whilst those in Asian and Black individuals were informative but less accurate. We estimate that the genotyping of circa 500,000 unrelated individuals will yield predictions between 66% and 82% of the SNP-heritability captured by common variants in our array. Prediction accuracies did not improve when including rarer SNPs or when fitting multiple traits jointly in multivariate models."," Adiposity/*genetics; Anthropometry; Basal Metabolism/*genetics; *Body Mass Index; Female; Genetic Association Studies; Genetic Variation; Genotype; Humans; Male; Models, Genetic; Obesity/*genetics; Phenotype; *Polymorphism, Single Nucleotide; *Waist-Hip Ratio",-2,,,,,
168,Gonzalez-Villa,2016,Artificial intelligence in medicine,A review on brain structures segmentation in magnetic resonance imaging,"BACKGROUND AND OBJECTIVES: Automatic brain structures segmentation in magnetic resonance images has been widely investigated in recent years with the goal of helping diagnosis and patient follow-up in different brain diseases. Here, we present a review of the state-of-the-art of automatic methods available in the literature ranging from structure specific segmentation methods to whole brain parcellation approaches. METHODS: We divide first the algorithms according to their target structures and then we propose a general classification based on their segmentation strategy, which includes atlas-based, learning-based, deformable, region-based and hybrid methods. We further discuss each category's strengths and weaknesses and analyze its performance in segmenting different brain structures providing a qualitative and quantitative comparison. RESULTS: We compare the results of the analyzed works for the following brain structures: hippocampus, thalamus, caudate nucleus, putamen, pallidum, amygdala, accumbens, lateral ventricles, and brainstem. The structures on which more works have focused on are the hippocampus and the caudate nucleus. In general, the accumbens (0.69 mean DSC) is the most difficult structure to segment whereas the structures that seem to get the best results are the brainstem, closely followed by the thalamus and the putamen with 0.88, 0.87 and 0.86 mean DSC, respectively. Atlas-based approaches achieve good results when segmenting the hippocampus (DSC between 0.75 and 0.90), thalamus (0.88-0.92) and lateral ventricles (0.83-0.93), while deformable methods perform good for caudate nucleus (0.84-0.91) and putamen segmentation (0.86-0.89). CONCLUSIONS: There is not yet a single automatic segmentation approach that can emerge as a standard for the clinical practice, providing accurate brain structures segmentation. Future trends need to focus on combining multi-atlas methods with learning-based or deformable approaches. Employing atlases to provide spatial robustness and modeling the structures appearance with supervised classifiers or Active Appearance Models could lead to improved segmentation results.", *Algorithms; Atlases as Topic; Brain/*diagnostic imaging; Hippocampus/diagnostic imaging; Humans; *Magnetic Resonance Imaging; *Automated segmentation methods; *Brain structures; *Review,-2,,,,,
169,Vuokko,2017,International journal of medical informatics,Impacts of structuring the electronic health record: Results of a systematic literature review from the perspective of secondary use of patient data,"PURPOSE: To explore the impacts that structuring of electronic health records (EHRs) has had from the perspective of secondary use of patient data as reflected in currently published literature. This paper presents the results of a systematic literature review aimed at answering the following questions; (1) what are the common methods of structuring patient data to serve secondary use purposes; (2) what are the common methods of evaluating patient data structuring in the secondary use context, and (3) what impacts or outcomes of EHR structuring have been reported from the secondary use perspective. METHODS: The reported study forms part of a wider systematic literature review on the impacts of EHR structuring methods and evaluations of their impact. The review was based on a 12-step systematic review protocol adapted from the Cochrane methodology. Original articles included in the study were divided into three groups for analysis and reporting based on their use focus: nursing documentation, medical use and secondary use (presented in this paper). The analysis from the perspective of secondary use of data includes 85 original articles from 1975 to 2010 retrieved from 15 bibliographic databases. RESULTS: The implementation of structured EHRs can be roughly divided into applications for documenting patient data at the point of care and application for retrieval of patient data (post hoc structuring). Two thirds of the secondary use articles concern EHR structuring methods which were still under development or in the testing phase. METHODS: of structuring patient data such as codes, terminologies, reference information models, forms or templates and documentation standards were usually applied in combination. Most of the identified benefits of utilizing structured EHR data for secondary use purposes concentrated on information content and quality or on technical quality and reliability, particularly in the case of Natural Language Processing (NLP) studies. A few individual articles evaluated impacts on care processes, productivity and costs, patient safety, care quality or other health impacts. In most articles these endpoints were usually discussed as goals of secondary use and less as evidence-supported impacts, resulting from the use of structured EHR data for secondary purposes. CONCLUSIONS: Further studies and more sound evaluation methods are needed for evidence on how EHRs are utilized for secondary purposes, and how structured documentation methods can serve different users' needs, e.g. administration, statistics and research and development, in parallel to medical use purposes.", *Documentation; Electronic Health Records/*organization & administration/standards/*statistics &; numerical data; Humans; Information Storage and Retrieval/*standards; Meaningful Use; Quality of Health Care; *Electronic health records; *Free text; *Secondary use of patient data; *Structured data; *Systematic literature review,-2,,,,,
170,Kadi,2017,International journal of medical informatics,Knowledge discovery in cardiology: A systematic literature review,"CONTEXT: Data mining (DM) provides the methodology and technology needed to transform huge amounts of data into useful information for decision making. It is a powerful process employed to extract knowledge and discover new patterns embedded in large data sets. Data mining has been increasingly used in medicine, particularly in cardiology. In fact, DM applications can greatly benefit all those involved in cardiology, such as patients, cardiologists and nurses. OBJECTIVE: The purpose of this paper is to review papers concerning the application of DM techniques in cardiology so as to summarize and analyze evidence regarding: (1) the DM techniques most frequently used in cardiology; (2) the performance of DM models in cardiology; (3) comparisons of the performance of different DM models in cardiology. METHOD: We performed a systematic literature review of empirical studies on the application of DM techniques in cardiology published in the period between 1 January 2000 and 31 December 2015. RESULTS: A total of 149 articles published between 2000 and 2015 were selected, studied and analyzed according to the following criteria: DM techniques and performance of the approaches developed. The results obtained showed that a significant number of the studies selected used classification and prediction techniques when developing DM models. Neural networks, decision trees and support vector machines were identified as being the techniques most frequently employed when developing DM models in cardiology. Moreover, neural networks and support vector machines achieved the highest accuracy rates and were proved to be more efficient than other techniques."," Cardiology/*education; Data Mining/*methods; Decision Trees; Models, Theoretical; Neural Networks (Computer); Support Vector Machine; *Cardiology; *Data mining; *Knowledge extraction; *Medical tasks",-1,,,,,
171,Gogovor,2017,International journal of medical informatics,Informing the development of an Internet-based chronic pain self-management program,"BACKGROUND: Self-management can optimize health outcomes for individuals with chronic pain (CP), an increasing fiscal and social burden in Canada. However, self-management is rarely integrated into the regular care (team activities and medical treatment) patients receive. Health information technology offers an opportunity to provide regular monitoring and exchange of information between patient and care team. OBJECTIVE: To identify information needs and gaps in chronic pain management as well as technology features to inform the development of an Internet-based self-management program. METHODS: Two methods were used. First was a structured literature review: electronic databases were searched up to 2015 with combinations of MeSH terms and text-words such as chronic pain, self-management, self-efficacy, technology, Internet-based, patient portal, and e-health. A narrative synthesis of the characteristics and content of Internet-based pain management programs emerging from the literature review and how they relate to gaps in chronic pain management were completed. Second, four audiotaped focus group sessions were conducted with individuals with chronic pain and caregivers (n=9) and health professionals (n=7) recruited from three multidisciplinary tertiary and rehabilitation centres. A thematic analysis of the focus group transcripts was conducted. RESULTS: Thirty-nine primary articles related to 20 patient-oriented Internet-based programs were selected. Gaps in CP management included lack of knowledge, limited access to health care, suboptimal care, and lack of self-management support. Overall, 14 themes related to information needs and gaps in care were identified by both health professionals and patients, three were exclusive to patients and five to health professionals. Common themes from the focus groups included patient education on chronic pain care, attitude-belief-culture, financial and legal issues, end-of-program crash, and motivational content. CONCLUSIONS: Internet-based programs contain automated, communication and decision support features that can address information and care gaps reported by patients and clinicians. However, focus groups identified functionalities not reported in the literature, non-medical and condition- and context-specific information, integration of personal health records, and the role of the different health professionals in chronic pain management were not identified. These gaps need to be considered in the future development of Internet-based programs. While the association between the mechanisms of Internet-based programs' features and outcomes is not clearly established, the results of this study indicate that interactivity, personalization and tailored messages, combined with therapist contact will maximize the effectiveness of an Internet-based chronic pain program in enhancing self-management.", Adult; Aged; Attitude; Canada; Caregivers; Chronic Pain/*therapy; Female; Focus Groups; Humans; *Internet; Male; Middle Aged; *Pain Management; Patient Education as Topic/methods; *Self Care; *Chronic pain; *Internet-based program; *Self-management; *e-health,-2,,,,,
172,Ouzzani,2016,Systematic reviews,Rayyan-a web and mobile app for systematic reviews,"BACKGROUND: Synthesis of multiple randomized controlled trials (RCTs) in a systematic review can summarize the effects of individual outcomes and provide numerical answers about the effectiveness of interventions. Filtering of searches is time consuming, and no single method fulfills the principal requirements of speed with accuracy. Automation of systematic reviews is driven by a necessity to expedite the availability of current best evidence for policy and clinical decision-making. We developed Rayyan ( http://rayyan.qcri.org ), a free web and mobile app, that helps expedite the initial screening of abstracts and titles using a process of semi-automation while incorporating a high level of usability. For the beta testing phase, we used two published Cochrane reviews in which included studies had been selected manually. Their searches, with 1030 records and 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan's users and collected feedback through a built-in feature. RESULTS: Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The ""taster"" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The ""suggestions"" and ""hints,"" based on the ""prediction model,"" appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users. CONCLUSIONS: Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.", Feedback; Humans; *Internet; *Mobile Applications/standards; Randomized Controlled Trials as Topic; *Research Design; *Review Literature as Topic; Time Factors; *Automation; *Evidence-based medicine; *Systematic reviews,2,,,,"Rayyan, Screening of abstracts",
173,Salamon,2016,PloS one,Towards the Automatic Classification of Avian Flight Calls for Bioacoustic Monitoring,"Automatic classification of animal vocalizations has great potential to enhance the monitoring of species movements and behaviors. This is particularly true for monitoring nocturnal bird migration, where automated classification of migrants' flight calls could yield new biological insights and conservation applications for birds that vocalize during migration. In this paper we investigate the automatic classification of bird species from flight calls, and in particular the relationship between two different problem formulations commonly found in the literature: classifying a short clip containing one of a fixed set of known species (N-class problem) and the continuous monitoring problem, the latter of which is relevant to migration monitoring. We implemented a state-of-the-art audio classification model based on unsupervised feature learning and evaluated it on three novel datasets, one for studying the N-class problem including over 5000 flight calls from 43 different species, and two realistic datasets for studying the monitoring scenario comprising hundreds of thousands of audio clips that were compiled by means of remote acoustic sensors deployed in the field during two migration seasons. We show that the model achieves high accuracy when classifying a clip to one of N known species, even for a large number of species. In contrast, the model does not perform as well in the continuous monitoring case. Through a detailed error analysis (that included full expert review of false positives and negatives) we show the model is confounded by varying background noise conditions and previously unseen vocalizations. We also show that the model needs to be parameterized and benchmarked differently for the continuous monitoring scenario. Finally, we show that despite the reduced performance, given the right conditions the model can still characterize the migration pattern of a specific species. The paper concludes with directions for future research."," Animal Migration; Animals; Area Under Curve; Automation; Birds/*classification/physiology; Flight, Animal/*physiology; ROC Curve; Seasons; Tape Recording; Vocalization, Animal",-2,,,,,
174,Ivliev,2016,PloS one,Drug Repositioning through Systematic Mining of Gene Coexpression Networks in Cancer,"Gene coexpression network analysis is a powerful ""data-driven"" approach essential for understanding cancer biology and mechanisms of tumor development. Yet, despite the completion of thousands of studies on cancer gene expression, there have been few attempts to normalize and integrate co-expression data from scattered sources in a concise ""meta-analysis"" framework. We generated such a resource by exploring gene coexpression networks in 82 microarray datasets from 9 major human cancer types. The analysis was conducted using an elaborate weighted gene coexpression network (WGCNA) methodology and identified over 3,000 robust gene coexpression modules. The modules covered a range of known tumor features, such as proliferation, extracellular matrix remodeling, hypoxia, inflammation, angiogenesis, tumor differentiation programs, specific signaling pathways, genomic alterations, and biomarkers of individual tumor subtypes. To prioritize genes with respect to those tumor features, we ranked genes within each module by connectivity, leading to identification of module-specific functionally prominent hub genes. To showcase the utility of this network information, we positioned known cancer drug targets within the coexpression networks and predicted that Anakinra, an anti-rheumatoid therapeutic agent, may be promising for development in colorectal cancer. We offer a comprehensive, normalized and well documented collection of >3000 gene coexpression modules in a variety of cancers as a rich data resource to facilitate further progress in cancer research."," Biomarkers, Tumor/genetics; Cell Differentiation/genetics; Cell Proliferation/genetics; Data Mining/methods; Drug Repositioning/methods; Gene Expression/*genetics; Gene Expression Profiling/methods; Gene Regulatory Networks/*genetics; Genomics/methods; Humans; Hypoxia/genetics; Inflammation/genetics; Neoplasms/*genetics; Signal Transduction/genetics",-2,Gene expression,,,,
176,Wallace,2016,Journal of machine learning research : JMLR,Extracting PICO Sentences from Clinical Trial Reports using Supervised Distant Supervision,"Systematic reviews underpin Evidence Based Medicine (EBM) by addressing precise clinical questions via comprehensive synthesis of all relevant published evidence. Authors of systematic reviews typically define a Population/Problem, Intervention, Comparator, and Outcome (a PICO criteria) of interest, and then retrieve, appraise and synthesize results from all reports of clinical trials that meet these criteria. Identifying PICO elements in the full-texts of trial reports is thus a critical yet time-consuming step in the systematic review process. We seek to expedite evidence synthesis by developing machine learning models to automatically extract sentences from articles relevant to PICO elements. Collecting a large corpus of training data for this task would be prohibitively expensive. Therefore, we derive distant supervision (DS) with which to train models using previously conducted reviews. DS entails heuristically deriving 'soft' labels from an available structured resource. However, we have access only to unstructured, free-text summaries of PICO elements for corresponding articles; we must derive from these the desired sentence-level annotations. To this end, we propose a novel method - supervised distant supervision (SDS) - that uses a small amount of direct supervision to better exploit a large corpus of distantly labeled instances by learning to pseudo-annotate articles using the available DS. We show that this approach tends to outperform existing methods with respect to automated PICO extraction.", Evidence-based medicine; data extraction; distant supervision; natural language processing; text mining,2,,,,PICO,
177,Yli-Huumo,2016,PloS one,Where Is Current Research on Blockchain Technology?-A Systematic Review,"Blockchain is a decentralized transaction and data management technology developed first for Bitcoin cryptocurrency. The interest in Blockchain technology has been increasing since the idea was coined in 2008. The reason for the interest in Blockchain is its central attributes that provide security, anonymity and data integrity without any third party organization in control of the transactions, and therefore it creates interesting research areas, especially from the perspective of technical challenges and limitations. In this research, we have conducted a systematic mapping study with the goal of collecting all relevant research on Blockchain technology. Our objective is to understand the current research topics, challenges and future directions regarding Blockchain technology from the technical perspective. We have extracted 41 primary papers from scientific databases. The results show that focus in over 80% of the papers is on Bitcoin system and less than 20% deals with other Blockchain applications including e.g. smart contracts and licensing. The majority of research is focusing on revealing and improving limitations of Blockchain from privacy and security perspectives, but many of the proposed solutions lack concrete evaluation on their effectiveness. Many other Blockchain scalability related challenges including throughput and latency have been left unstudied. On the basis of this study, recommendations on future research directions are provided for researchers.", Cost-Benefit Analysis; Data Mining/economics/*trends; Humans; Research/*trends; Technology/*economics/trends,-2,,,,,
178,Nieto,2016,PloS one,An Empirical Biomarker-Based Calculator for Cystic Index in a Model of Autosomal Recessive Polycystic Kidney Disease-The Nieto-Narayan Formula,"Autosomal recessive polycystic kidney disease (ARPKD) is associated with progressive enlargement of the kidneys fuelled by the formation and expansion of fluid-filled cysts. The disease is congenital and children that do not succumb to it during the neonatal period will, by age 10 years, more often than not, require nephrectomy+renal replacement therapy for management of both pain and renal insufficiency. Since increasing cystic index (CI; percent of kidney occupied by cysts) drives both renal expansion and organ dysfunction, management of these patients, including decisions such as elective nephrectomy and prioritization on the transplant waitlist, could clearly benefit from serial determination of CI. So also, clinical trials in ARPKD evaluating the efficacy of novel drug candidates could benefit from serial determination of CI. Although ultrasound is currently the imaging modality of choice for diagnosis of ARPKD, its utilization for assessing disease progression is highly limited. Magnetic resonance imaging or computed tomography, although more reliable for determination of CI, are expensive, time-consuming and somewhat impractical in the pediatric population. Using a well-established mammalian model of ARPKD, we undertook a big data-like analysis of minimally- or non-invasive blood and urine biomarkers of renal injury/dysfunction to derive a family of equations for estimating CI. We then applied a signal averaging protocol to distill these equations to a single empirical formula for calculation of CI. Such a formula will eventually find use in identifying and monitoring patients at high risk for progressing to end-stage renal disease and aid in the conduct of clinical trials."," Animals; *Biomarkers/blood/urine; Blood Urea Nitrogen; Child; Creatinine/blood; Cystatin C/blood; Cysts/pathology; Hepatitis A Virus Cellular Receptor 1/blood; Humans; Interleukin-18/blood; Kidney/diagnostic imaging/metabolism/physiopathology; Kidney Transplantation; Lipocalin-2/blood; Magnetic Resonance Imaging; Mice; Polycystic Kidney, Autosomal Recessive/*blood/diagnostic imaging/pathology/*urine; Rats; Renal Insufficiency/*blood/pathology/*urine; Severity of Illness Index; Ultrasonography",-2,,,,,
179,Pawloski,2017,Journal of the American Medical Informatics Association : JAMIA,Predicting neutropenia risk in patients with cancer using electronic data,"Objectives: Clinical guidelines recommending the use of myeloid growth factors are largely based on the prescribed chemotherapy regimen. The guidelines suggest that oncologists consider patient-specific characteristics when prescribing granulocyte-colony stimulating factor (G-CSF) prophylaxis; however, a mechanism to quantify individual patient risk is lacking. Readily available electronic health record (EHR) data can provide patient-specific information needed for individualized neutropenia risk estimation. An evidence-based, individualized neutropenia risk estimation algorithm has been developed. This study evaluated the automated extraction of EHR chemotherapy treatment data and externally validated the neutropenia risk prediction model. Materials and Methods: A retrospective cohort of adult patients with newly diagnosed breast, colorectal, lung, lymphoid, or ovarian cancer who received the first cycle of a cytotoxic chemotherapy regimen from 2008 to 2013 were recruited from a single cancer clinic. Electronically extracted EHR chemotherapy treatment data were validated by chart review. Neutropenia risk stratification was conducted and risk model performance was assessed using calibration and discrimination. Results: Chemotherapy treatment data electronically extracted from the EHR were verified by chart review. The neutropenia risk prediction tool classified 126 patients (57%) as being low risk for febrile neutropenia, 44 (20%) as intermediate risk, and 51 (23%) as high risk. The model was well calibrated (Hosmer-Lemeshow goodness-of-fit test = 0.24). Discrimination was adequate and slightly less than in the original internal validation (c-statistic 0.75 vs 0.81). Conclusion: Chemotherapy treatment data were electronically extracted from the EHR successfully. The individualized neutropenia risk prediction model performed well in our retrospective external cohort.", Aged; *Algorithms; Antineoplastic Combined Chemotherapy Protocols/*adverse effects; *Electronic Health Records; Female; Granulocyte Colony-Stimulating Factor/therapeutic use; Humans; Information Storage and Retrieval; Logistic Models; Male; Middle Aged; Neoplasms/*complications/drug therapy; Neutropenia/*chemically induced; ROC Curve; Retrospective Studies; Risk Assessment/*methods; chemotherapy; clinical decision support systems; computer-based decision support; febrile neutropenia; granulocyte-colony stimulating factor; risk model,-2,,,,,
180,Cristea,2016,PloS one,The Effectiveness of Cognitive Bias Modification Interventions for Substance Addictions: A Meta-Analysis,"BACKGROUND AND AIMS: Cognitive bias modification (CBM) interventions, presumably targeting automatic processes, are considered particularly promising for addictions. We conducted a meta-analysis examining randomized controlled trials (RCTs) of CBM for substance addiction outcomes. METHODS: Studies were identified through systematic searches in bibliographical databases. We included RCTs of CBM interventions, alone or in combination with other treatments, for any type of addiction. We examined trial risk of bias, publication bias and possible moderators. Effects sizes were computed for post-test and follow-up, using a random-effects model. We grouped outcome measures and reported results for addiction (all related measures), craving and cognitive bias. RESULTS: We identified 25 trials, 18 for alcohol problems, and 7 for smoking. At post-test, there was no significant effect of CBM for addiction, g = 0.08 (95% CI -0.02 to 0.18) or craving, g = 0.05 (95% CI -0.06 to 0.16), but there was a significant, moderate effect on cognitive bias, g = 0.60 (95% CI 0.39 to 0.79). Results were similar for alcohol and smoking outcomes taken separately. Follow-up addiction outcomes were reported in 7 trials, resulting in a small but significant effect of CBM, g = 0.18 (95% CI 0.03 to 0.32). Results for addiction and craving did not differ by substance type, sample type, delivery setting, bias targeted or number of sessions. Risk of bias was high or uncertain in most trials, for most criteria considered. Meta-regression analyses revealed significant inverse relationships between risk of bias and effect sizes for addiction outcomes and craving. The relationship between cognitive bias and respectively addiction ESs was not significant. There was consistent evidence of publication bias in the form of funnel plot asymmetry. CONCLUSIONS: Our results cast serious doubts on the clinical utility of CBM interventions for addiction problems, but sounder methodological trials are necessary before this issue can be settled. We found no indication that positive effects on biases translate into effects on addiction outcomes.", Bias; *Cognitive Behavioral Therapy; Female; Humans; Male; Outcome Assessment (Health Care); Substance-Related Disorders/*therapy,-2,,,,,
181,Brown,2017,Journal of the American Medical Informatics Association : JAMIA,A systematic review of the types and causes of prescribing errors generated from using computerized provider order entry systems in primary and secondary care,"Objective: To understand the different types and causes of prescribing errors associated with computerized provider order entry (CPOE) systems, and recommend improvements in these systems. Materials and Methods: We conducted a systematic review of the literature published between January 2004 and June 2015 using three large databases: the Cumulative Index to Nursing and Allied Health Literature, Embase, and Medline. Studies that reported qualitative data about the types and causes of these errors were included. A narrative synthesis of all eligible studies was undertaken. Results: A total of 1185 publications were identified, of which 34 were included in the review. We identified 8 key themes associated with CPOE-related prescribing errors: computer screen display, drop-down menus and auto-population, wording, default settings, nonintuitive or inflexible ordering, repeat prescriptions and automated processes, users' work processes, and clinical decision support systems. Displaying an incomplete list of a patient's medications on the computer screen often contributed to prescribing errors. Lack of system flexibility resulted in users employing error-prone workarounds, such as the addition of contradictory free-text comments. Users' misinterpretations of how text was presented in CPOE systems were also linked with the occurrence of prescribing errors. Discussion and Conclusions: Human factors design is important to reduce error rates. Drop-down menus should be designed with safeguards to decrease the likelihood of selection errors. Development of more sophisticated clinical decision support, which can perform checks on free-text, may also prevent errors. Further research is needed to ensure that systems minimize error likelihood and meet users' workflow expectations.", Drug Prescriptions; Ergonomics; Humans; *Medical Order Entry Systems; *Medication Errors/prevention & control; alerts; clinical decision support; computerized provider order entry; decision-making; medication errors; patient safety,-2,Provider order entry systems ,,,,
182,Varghese,2016,Studies in health technology and informatics,Key Data Elements in Myeloid Leukemia,"Data standards consisting of key data elements for clinical routine and trial documentation harmonize documentation within and across different health care institutions making documentation more efficient and improving scientific data analysis. This work focusses on the field of myeloid leukemia (ML), where a semantic core of common data elements (CDEs) in routine and trial documentation is established by automatic UMLS-based form analysis of existing documentation models. These CDEs (n = 227) were initially reviewed and commented by leukemia experts before they were systematically surveyed by an international voting process through seven hematologists of four countries. The total agreement score was 86%. 116 elements (51%) of these share an agreement score of 100%. This work generated CDEs with language-independent semantic codes and international clinical expert review to build a first approach towards an international data standard for ML. A first version of the CDE list is implemented in the data standard Operational Data Model and additional other data formats for reuse in different medical information systems."," Clinical Trials as Topic; Data Collection; Documentation/*standards; Humans; *Leukemia, Myeloid; Semantics",1,,,UMLS,,
183,Chen,2017,Journal of the American Medical Informatics Association : JAMIA,Identifying collaborative care teams through electronic medical record utilization patterns,"Objective: The goal of this investigation was to determine whether automated approaches can learn patient-oriented care teams via utilization of an electronic medical record (EMR) system. Materials and Methods: To perform this investigation, we designed a data-mining framework that relies on a combination of latent topic modeling and network analysis to infer patterns of collaborative teams. We applied the framework to the EMR utilization records of over 10 000 employees and 17 000 inpatients at a large academic medical center during a 4-month window in 2010. Next, we conducted an extrinsic evaluation of the patterns to determine the plausibility of the inferred care teams via surveys with knowledgeable experts. Finally, we conducted an intrinsic evaluation to contextualize each team in terms of collaboration strength (via a cluster coefficient) and clinical credibility (via associations between teams and patient comorbidities). Results: The framework discovered 34 collaborative care teams, 27 (79.4%) of which were confirmed as administratively plausible. Of those, 26 teams depicted strong collaborations, with a cluster coefficient > 0.5. There were 119 diagnostic conditions associated with 34 care teams. Additionally, to provide clarity on how the survey respondents arrived at their determinations, we worked with several oncologists to develop an illustrative example of how a certain team functions in cancer care. Discussion: Inferred collaborative teams are plausible; translating such patterns into optimized collaborative care will require administrative review and integration with management practices. Conclusions: EMR utilization records can be mined for collaborative care patterns in large complex medical centers.", Cooperative Behavior; *Data Mining; Electronic Health Records/*statistics & numerical data; Humans; Interprofessional Relations; *Patient Care Team; Patient-Centered Care; collaborative networks; data mining; electronic medical records; health care organization modeling,-2,,Electronic medical record,,,
184,Shemilt,2016,Systematic reviews,Use of cost-effectiveness analysis to compare the efficiency of study identification methods in systematic reviews,"BACKGROUND: Meta-research studies investigating methods, systems, and processes designed to improve the efficiency of systematic review workflows can contribute to building an evidence base that can help to increase value and reduce waste in research. This study demonstrates the use of an economic evaluation framework to compare the costs and effects of four variant approaches to identifying eligible studies for consideration in systematic reviews. METHODS: A cost-effectiveness analysis was conducted using a basic decision-analytic model, to compare the relative efficiency of 'safety first', 'double screening', 'single screening' and 'single screening with text mining' approaches in the title-abstract screening stage of a 'case study' systematic review about undergraduate medical education in UK general practice settings. Incremental cost-effectiveness ratios (ICERs) were calculated as the 'incremental cost per citation 'saved' from inappropriate exclusion' from the review. Resource use and effect parameters were estimated based on retrospective analysis of 'review process' meta-data curated alongside the 'case study' review, in conjunction with retrospective simulation studies to model the integrated use of text mining. Unit cost parameters were estimated based on the 'case study' review's project budget. A base case analysis was conducted, with deterministic sensitivity analyses to investigate the impact of variations in values of key parameters. RESULTS: Use of 'single screening with text mining' would have resulted in title-abstract screening workload reductions (base case analysis) of >60 % compared with other approaches. Across modelled scenarios, the 'safety first' approach was, consistently, equally effective and less costly than conventional 'double screening'. Compared with 'single screening with text mining', estimated ICERs for the two non-dominated approaches (base case analyses) ranged from pound1975 ('single screening' without a 'provisionally included' code) to pound4427 ('safety first' with a 'provisionally included' code) per citation 'saved'. Patterns of results were consistent between base case and sensitivity analyses. CONCLUSIONS: Alternatives to the conventional 'double screening' approach, integrating text mining, warrant further consideration as potentially more efficient approaches to identifying eligible studies for systematic reviews. Comparable economic evaluations conducted using other systematic review datasets are needed to determine the generalisability of these findings and to build an evidence base to inform guidance for review authors.", *Cost-Benefit Analysis; Data Mining/*methods; Humans; Patient Safety; *Research Design,1,,,"Study identification, Screening",,
185,Meghji,2016,PloS one,A Systematic Review of the Prevalence and Pattern of Imaging Defined Post-TB Lung Disease,"BACKGROUND: Tuberculosis is an important risk factor for chronic respiratory disease in resource poor settings. The persistence of abnormal spirometry and symptoms after treatment are well described, but the structural abnormalities underlying these changes remain poorly defined, limiting our ability to phenotype post-TB lung disease in to meaningful categories for clinical management, prognostication, and ongoing research. The relationship between post-TB lung damage and patient-centred outcomes including functional impairment, respiratory symptoms, and health related quality of life also remains unclear. METHODS: We performed a systematic literature review to determine the prevalence and pattern of imaging-defined lung pathology in adults after medical treatment for pleural, miliary, or pulmonary TB disease. Data were collected on study characteristics, and the modality, timing, and findings of thoracic imaging. The proportion of studies relating imaging findings to spirometry results and patient morbidity was recorded. Study quality was assessed using a modified Newcastle-Ottowa score. (Prospero Registration number CRD42015027958). RESULTS: We identified 37 eligible studies. The principle features seen on CXR were cavitation (8.3-83.7%), bronchiectasis (4.3-11.2%), and fibrosis (25.0-70.4%), but prevalence was highly variable. CT imaging identified a wider range of residual abnormalities than CXR, including nodules (25.0-55.8%), consolidation (3.7-19.2%), and emphysema (15.0-45.0%). The prevalence of cavitation was generally lower (7.4-34.6%) and bronchiectasis higher (35.0-86.0%) on CT vs. CXR imaging. A paucity of prospective data, and data from HIV-infected adults and sub-Saharan Africa (sSA) was noted. Few studies related structural damage to physiological impairment, respiratory symptoms, or patient morbidity. CONCLUSIONS: Post-TB structural lung pathology is common. Prospective data are required to determine the evolution of this lung damage and its associated morbidity over time. Further data are required from HIV-infected groups and those living in sSA."," Humans; Image Processing, Computer-Assisted/*methods; Pattern Recognition, Automated/*methods; Prevalence; Tomography, X-Ray Computed/*methods; Tuberculosis, Pulmonary/*diagnostic imaging/*epidemiology/pathology; United Kingdom/epidemiology",-2,,,,,
186,Lyell,2017,Journal of the American Medical Informatics Association : JAMIA,Automation bias and verification complexity: a systematic review,"Introduction: While potentially reducing decision errors, decision support systems can introduce new types of errors. Automation bias (AB) happens when users become overreliant on decision support, which reduces vigilance in information seeking and processing. Most research originates from the human factors literature, where the prevailing view is that AB occurs only in multitasking environments. Objectives: This review seeks to compare the human factors and health care literature, focusing on the apparent association of AB with multitasking and task complexity. Data sources: EMBASE, Medline, Compendex, Inspec, IEEE Xplore, Scopus, Web of Science, PsycINFO, and Business Source Premiere from 1983 to 2015. Study selection: Evaluation studies where task execution was assisted by automation and resulted in errors were included. Participants needed to be able to verify automation correctness and perform the task manually. Methods: Tasks were identified and grouped. Task and automation type and presence of multitasking were noted. Each task was rated for its verification complexity. Results: Of 890 papers identified, 40 met the inclusion criteria; 6 were in health care. Contrary to the prevailing human factors view, AB was found in single tasks, typically involving diagnosis rather than monitoring, and with high verification complexity. Limitations: The literature is fragmented, with large discrepancies in how AB is reported. Few studies reported the statistical significance of AB compared to a control condition. Conclusion: AB appears to be associated with the degree of cognitive load experienced in decision tasks, and appears to not be uniquely associated with multitasking. Strategies to minimize AB might focus on cognitive load reduction."," *Attitude to Computers; Automation; Bias; *Decision Support Systems, Clinical; Humans; clinical cognitive biases; complexity; decision support systems",-2,,,,,
187,Richesson,2016,Artificial intelligence in medicine,"Clinical phenotyping in selected national networks: demonstrating the need for high-throughput, portable, and computational methods","OBJECTIVE: The combination of phenomic data from electronic health records (EHR) and clinical data repositories with dense biological data has enabled genomic and pharmacogenomic discovery, a first step toward precision medicine. Computational methods for the identification of clinical phenotypes from EHR data will advance our understanding of disease risk and drug response, and support the practice of precision medicine on a national scale. METHODS: Based on our experience within three national research networks, we summarize the broad approaches to clinical phenotyping and highlight the important role of these networks in the progression of high-throughput phenotyping and precision medicine. We provide supporting literature in the form of a non-systematic review. RESULTS: The practice of clinical phenotyping is evolving to meet the growing demand for scalable, portable, and data driven methods and tools. The resources required for traditional phenotyping algorithms from expert defined rules are significant. In contrast, machine learning approaches that rely on data patterns will require fewer clinical domain experts and resources. CONCLUSIONS: Machine learning approaches that generate phenotype definitions from patient features and clinical profiles will result in truly computational phenotypes, derived from data rather than experts. Research networks and phenotype developers should cooperate to develop methods, collaboration platforms, and data standards that will enable computational phenotyping and truly modernize biomedical research and precision medicine.", *Algorithms; *Electronic Health Records; Genomics; Humans; *Machine Learning; *Phenotype; *Precision Medicine; *Clinical phenotyping; *Networked research,-2,,,,,
188,Alberdi,2016,Artificial intelligence in medicine,On the early diagnosis of Alzheimer's Disease from multimodal signals: A survey,"INTRODUCTION: The number of Alzheimer's Disease (AD) patients is increasing with increased life expectancy and 115.4 million people are expected to be affected in 2050. Unfortunately, AD is commonly diagnosed too late, when irreversible damages have been caused in the patient. OBJECTIVE: An automatic, continuous and unobtrusive early AD detection method would be required to improve patients' life quality and avoid big healthcare costs. Thus, the objective of this survey is to review the multimodal signals that could be used in the development of such a system, emphasizing on the accuracy that they have shown up to date for AD detection. Some useful tools and specific issues towards this goal will also have to be reviewed. METHODS: An extensive literature review was performed following a specific search strategy, inclusion criteria, data extraction and quality assessment in the Inspec, Compendex and PubMed databases. RESULTS: This work reviews the extensive list of psychological, physiological, behavioural and cognitive measurements that could be used for AD detection. The most promising measurements seem to be magnetic resonance imaging (MRI) for AD vs control (CTL) discrimination with an 98.95% accuracy, while electroencephalogram (EEG) shows the best results for mild cognitive impairment (MCI) vs CTL (97.88%) and MCI vs AD distinction (94.05%). Available physiological and behavioural AD datasets are listed, as well as medical imaging analysis steps and neuroimaging processing toolboxes. Some issues such as ""label noise"" and multi-site data are discussed. CONCLUSIONS: The development of an unobtrusive and transparent AD detection system should be based on a multimodal system in order to take full advantage of all kinds of symptoms, detect even the smallest changes and combine them, so as to detect AD as early as possible. Such a multimodal system might probably be based on physiological monitoring of MRI or EEG, as well as behavioural measurements like the ones proposed along the article. The mentioned AD datasets and image processing toolboxes are available for their use towards this goal. Issues like ""label noise"" and multi-site neuroimaging incompatibilities may also have to be overcome, but methods for this purpose are already available."," Alzheimer Disease/*diagnosis; *Early Diagnosis; Humans; *Image Processing, Computer-Assisted; Magnetic Resonance Imaging; *Alzheimer's Disease; *Behaviour; *Early detection; *Multimodality; *Physiology",-2,,,,,
189,Roberts,2017,Journal of the American Medical Informatics Association : JAMIA,Biomedical informatics advancing the national health agenda: the AMIA 2015 year-in-review in clinical and consumer informatics,"The field of biomedical informatics experienced a productive 2015 in terms of research. In order to highlight the accomplishments of that research, elicit trends, and identify shortcomings at a macro level, a 19-person team conducted an extensive review of the literature in clinical and consumer informatics. The result of this process included a year-in-review presentation at the American Medical Informatics Association Annual Symposium and a written report (see supplemental data). Key findings are detailed in the report and summarized here. This article organizes the clinical and consumer health informatics research from 2015 under 3 themes: the electronic health record (EHR), the learning health system (LHS), and consumer engagement. Key findings include the following: (1) There are significant advances in establishing policies for EHR feature implementation, but increased interoperability is necessary for these to gain traction. (2) Decision support systems improve practice behaviors, but evidence of their impact on clinical outcomes is still lacking. (3) Progress in natural language processing (NLP) suggests that we are approaching but have not yet achieved truly interactive NLP systems. (4) Prediction models are becoming more robust but remain hampered by the lack of interoperable clinical data records. (5) Consumers can and will use mobile applications for improved engagement, yet EHR integration remains elusive."," *Consumer Health Informatics; Humans; Meaningful Use; *Medical Informatics; Patient Participation; Public Health Informatics; Societies, Medical; United States; biomedical informatics; consumer engagement; electronic health records; learning health system; year in review",-2,,,,,
190,David,2016,PloS one,Comorbid Analysis of Genes Associated with Autism Spectrum Disorders Reveals Differential Evolutionary Constraints,"The burden of comorbidity in Autism Spectrum Disorder (ASD) is substantial. The symptoms of autism overlap with many other human conditions, reflecting common molecular pathologies suggesting that cross-disorder analysis will help prioritize autism gene candidates. Genes in the intersection between autism and related conditions may represent nonspecific indicators of dysregulation while genes unique to autism may play a more causal role. Thorough literature review allowed us to extract 125 ICD-9 codes comorbid to ASD that we mapped to 30 specific human disorders. In the present work, we performed an automated extraction of genes associated with ASD and its comorbid disorders, and found 1031 genes involved in ASD, among which 262 are involved in ASD only, with the remaining 779 involved in ASD and at least one comorbid disorder. A pathway analysis revealed 13 pathways not involved in any other comorbid disorders and therefore unique to ASD, all associated with basal cellular functions. These pathways differ from the pathways associated with both ASD and its comorbid conditions, with the latter being more specific to neural function. To determine whether the sequence of these genes have been subjected to differential evolutionary constraints, we studied long term constraints by looking into Genomic Evolutionary Rate Profiling, and showed that genes involved in several comorbid disorders seem to have undergone more purifying selection than the genes involved in ASD only. This result was corroborated by a higher dN/dS ratio for genes unique to ASD as compare to those that are shared between ASD and its comorbid disorders. Short-term evolutionary constraints showed the same trend as the pN/pS ratio indicates that genes unique to ASD were under significantly less evolutionary constraint than the genes associated with all other disorders."," Autism Spectrum Disorder/*complications/*genetics; Cluster Analysis; Databases, Genetic; Humans; International Classification of Diseases",-2,,,,,
191,Reed,2016,Systematic reviews,The HCV care continuum among people who use drugs: protocol for a systematic review and meta-analysis,"INTRODUCTION: The diagnosis, management, and treatment for hepatitis C virus (HCV) infection (the ""HCV care continuum"") have improved in recent years. People who use drugs (PWUD) have a prevalence of HCV infection from 30 to 70 %, yet rates of testing, engagement in care, and treatment for HCV are disproportionately low compared to other populations. Delineating the progression of PWUD through the steps in the HCV care continuum in the USA is important in informing efforts to improve HCV outcomes among PWUD. METHODS/DESIGN: Scientific databases will be searched using a comprehensive automated search strategy; gray literature and reference lists will be manually searched. Eligible reports will provide original research data related to the HCV care continuum in the USA including proportions of PWUD engaging in the following discrete steps: screening/testing, engagement in care (including receiving an HCV clinical assessment), treatment initiation and completion, and rates of those with successful HCV treatment. A quality-rating tool will be developed to ascertain the level of bias (including selection bias) in each report, and a quality score will be assigned to each eligible report. A tool adapted from the Pragmatic Explanatory Continuum Indicator Summary-2 instrument will be developed to assess the extent to which an included report reflects an effectiveness or efficacy study design. Pooled estimates and measures of association will be calculated using random effects models, and heterogeneity will be assessed at each stage of data synthesis. DISCUSSION: Through this review, we hope to quantify the proportion of PWUD at each progressive step and to help identify key individual, social, and structural points of leakage in the HCV care continuum for PWUD. In meeting these objectives, we will identify predictors to progress along the HCV care continuum, which can be used to inform policy to directly improve HCV care for PWUD. SYSTEMATIC REVIEW REGISTRATION: PROSPERO CRD42016034113.", *Continuity of Patient Care; *Drug Users; Health Services Accessibility; *Hepacivirus; Hepatitis C/etiology/*therapy/virology; Humans; Research Design; Substance-Related Disorders/*complications; Systematic Reviews as Topic; *Healthcare access; *Hepatitis c; *Hepatitis c care continuum; *Meta-analysis; *People who use drugs; *Systematic review,-2,,,,,
192,Wang,2017,Journal of the American Medical Informatics Association : JAMIA,Use of electronic healthcare records to identify complex patients with atrial fibrillation for targeted intervention,"Background: Practice guidelines recommend anticoagulation therapy for patients with atrial fibrillation (AF) who have other risk factors putting them at an elevated risk of stroke. These patients remain undertreated, but, with increasing use of electronic healthcare records (EHRs), it may be possible to identify candidates for treatment. Objective: To test algorithms for identifying AF patients who also have known risk factors for stroke and major bleeding using EHR data. Materials and Methods: We evaluated the performance of algorithms using EHR data from the Partners Healthcare System at identifying AF patients and 16 additional conditions that are risk factors in the CHA 2 DS 2 -VASc and HAS-BLED risk scores for stroke and major bleeding. Algorithms were based on information contained in problem lists, billing codes, laboratory data, prescription data, vital status, and clinical notes. The performance of candidate algorithms in 1000 bootstrap resamples was compared to a gold standard of manual chart review by experienced resident physicians. Results: : Physicians reviewed 480 patient charts. For 11 conditions, the median positive predictive value (PPV) of the EHR-derived algorithms was greater than 0.90. Although the PPV for some risk factors was poor, the median PPV for identifying patients with a CHA 2 DS 2 -VASc score >/=2 or a HAS-BLED score >/=3 was 1.00 and 0.92, respectively. Discussion: We developed and tested a set of algorithms to identify AF patients and known risk factors for stroke and major bleeding using EHR data. Algorithms such as these can be built into EHR systems to facilitate informed decision making and help shift population health management efforts towards patients with the greatest need.", *Algorithms; Anticoagulants/adverse effects/therapeutic use; Atrial Fibrillation/complications/*diagnosis/drug therapy; *Electronic Health Records; Hemorrhage/etiology; Humans; Natural Language Processing; Risk Assessment/methods; Risk Factors; Stroke/etiology; algorithms; anticoagulation; chronic disease; outcomes; quality improvement; stroke,-2,,,,,
193,Tsoromokos,2016,Studies in health technology and informatics,Design of an Innovative Information System for the Intensive Care Unit in a Public Hospital,"The health sector is increasingly focused on the use of Communication Technology (ICT) Information and Communication. New technologies which introduced in health, should lead to lower cost of procedures, saving employees' working time and immediate and secure data storages for easy future search or meta-analysis. The DPP4ICU application which presented in this document, allows at the Intensive Care Unit's nurses (ICU) to enter directly the handwritten accountability, in the Organization Information System. Through this application is accelerated the proper completion of a document and is improved data quality. The application provides the ability to authorized users to exchange information with an automated manner."," Communication; Documentation/*methods; *Handwriting; Hospitals, Public/organization & administration; Humans; Information Systems/*organization & administration; Intensive Care Units/*organization & administration; *Nursing Staff, Hospital; Software Design",-2,,,,,
194,Carter,2016,Studies in health technology and informatics,Finding 'Evidence of Absence' in Medical Notes: Using NLP for Clinical Inferencing,"Extracting evidence of the absence of a target of interest from medical text can be useful in clinical inferencing. The purpose of our study was to develop a natural language processing (NLP) pipelineto identify the presence of indwelling urinary catheters from electronic medical notes to aid in detection of catheter-associated urinary tract infections (CAUTI). Finding clear evidence that a patient does not have an indwelling urinary catheter is useful in making a determination regarding CAUTI. We developed a lexicon of seven core concepts to infer the absence of a urinary catheter. Of the 990,391 concepts extractedby NLP from a large corpus of 744,285 electronic medical notes from 5589 hospitalized patients, 63,516 were labeled as evidence of absence.Human review revealed three primary causes for false negatives. The lexicon and NLP pipeline were refined using this information, resulting in outputs with an acceptable false positive rate of 11%.", Catheter-Related Infections/*diagnosis; Diagnostic Errors; Documentation/*statistics & numerical data; Electronic Health Records/*statistics & numerical data; Humans; Inpatients; *Natural Language Processing; Urinary Catheters/*adverse effects,-2,,,,,
195,Topaz,2016,Studies in health technology and informatics,Mining Clinicians' Electronic Documentation to Identify Heart Failure Patients with Ineffective Self-Management: A Pilot Text-Mining Study,"Effective self-management can decrease up to 50% of heart failure hospitalizations. Unfortunately, self-management by patients with heart failure remains poor. This pilot study aimed to explore the use of text-mining to identify heart failure patients with ineffective self-management. We first built a comprehensive self-management vocabulary based on the literature and clinical notes review. We then randomly selected 545 heart failure patients treated within Partners Healthcare hospitals (Boston, MA, USA) and conducted a regular expression search with the compiled vocabulary within 43,107 interdisciplinary clinical notes of these patients. We found that 38.2% (n = 208) patients had documentation of ineffective heart failure self-management in the domains of poor diet adherence (28.4%), missed medical encounters (26.4%) poor medication adherence (20.2%) and non-specified self-management issues (e.g., ""compliance issues"", 34.6%). We showed the feasibility of using text-mining to identify patients with ineffective self-management. More natural language processing algorithms are needed to help busy clinicians identify these patients."," Boston/epidemiology; *Data Mining; Electronic Health Records/classification/*statistics & numerical data; Heart Failure/*diagnosis/epidemiology/*therapy; Humans; Natural Language Processing; Outcome Assessment (Health Care)/*methods; Patient Compliance/*statistics & numerical data; Pilot Projects; Prevalence; Reproducibility of Results; Risk Assessment; Self Care; Sensitivity and Specificity; Terminology as Topic; Treatment Failure; Treatment Outcome; Vocabulary, Controlled",-2,,,,,
196,Yu,2016,Studies in health technology and informatics,Development and Appraisal of Multiple Accounting Record System (Mars),"UNLABELLED: The aim of the system is to achieve simplification of workflow, reduction of recording time, and increase the income for the study hospital. METHODS: The project team decided to develop a multiple accounting record system that generates the account records based on the nursing records automatically, reduces the time and effort for nurses to review the procedure and provide another note of material consumption. Three configuration files were identified to demonstrate the relationship of treatments and reimbursement items. RESULTS: The workflow was simplified. The nurses averagely reduced 10 minutes of daily recording time, and the reimbursement points have been increased by 7.49%. CONCLUSION: The project streamlined the workflow and provides the institute a better way in finical management."," *Accounts Payable and Receivable; Economics, Nursing/*organization & administration; Electronic Health Records/*economics; Financial Management, Hospital/*organization & administration; Health Care Costs/*statistics & numerical data; Hospital Information Systems/organization & administration; Management Information Systems/*economics; Taiwan",-2,,,,,
197,Millar,2016,Studies in health technology and informatics,The Need for a Global Language - SNOMED CT Introduction,"SNOMED CT is the most comprehensive, multilingual clinical healthcare terminology in the world. It is a resource with comprehensive, scientifically validated clinical content. SNOMED CT enables consistent, processable representation of clinical content in electronic health records. When implemented in software applicationsSNOMED CT can be used to represent clinically relevant information consistently, reliabl comprehensively as an integral part of producing electronic health information. SNOMED CT supports the development of comprehensive high-quality clinical content in health records. It provides a standardized way to represent clinical phrases captured by the healthcare professional and enables automatic interpretation of these. SNOMED CT is a clinically validated, semantically rich, controlled vocabulary that facilitates evolutionary growth in expressivity to meet emerging requirements. SNOMED CT based clinical information benefits individual patients and clinicians as well as populations and it supports evidence based care. The use of an Electronic Health Record (EHR) improves communication and increases the availability of relevant information. IHTSDO works with other standards oganisations to ensure interoperability and a key area has been the work with ICN to enable the use of ICNP and SNOMED CT by the nursing profession internationally.", Electronic Health Records/*standards; Guideline Adherence/standards; Information Storage and Retrieval/*standards; Meaningful Use/standards; Medical Record Linkage/standards; Nursing Records/*standards; *Practice Guidelines as Topic; *Systematized Nomenclature of Medicine; *Terminology as Topic,1,,,Vocabulary,,
198,Choi,2016,Studies in health technology and informatics,Exploration of Risk Factors for Falls Using Electronic Nursing Records,"INTRODUCTION: The purpose was to identify fall risk factors between admission day and fall occurred day using electronic nursing records and the Morse Fall Scale (MFS). METHODS: The MFS and fall related data were obtained through retrospective chart review from June 1, 2014 to May 31, 2015. Descriptive statistics and McNemar test were used for statistical tests. RESULTS: Fall was evaluated in 447 events, 16 patients experienced recurrent fall. Pain, emotional distress, urinary problems and fever were significant differences between admission day and fall occurred day. There were explored significant MFS risk factors in risk group, history of falling, second diagnosis, IV catheter status, medication concerning fall risk, mental status, general weakness and gait in MFS subscales. DISCUSSION: Routine fall screening is important for early detection of fall. Identification of high-risk group and using fall prevention guidelines could improve prevention of fall.", Accidental Falls/*prevention & control/*statistics & numerical data; Data Mining/*methods; Electronic Health Records/*statistics & numerical data; Female; Humans; Male; Nursing Care/statistics & numerical data; Nursing Records/*statistics & numerical data; Population Surveillance/*methods; Prevalence; Republic of Korea/epidemiology; Risk Factors,-2,,,,,
199,Hausner,2016,Journal of clinical epidemiology,Prospective comparison of search strategies for systematic reviews: an objective approach yielded higher sensitivity than a conceptual one,"BACKGROUND: In the development of search strategies for systematic reviews, ""conceptual approaches"" are generally recommended to identify appropriate search terms for those parts of the strategies for which no validated search filters exist. However, ""objective approaches"" based on search terms identified by text analysis are increasingly being applied. OBJECTIVES: To prospectively compare an objective with a conceptual approach for the development of search strategies. METHODS: Two different MEDLINE search strategies were developed in parallel for five systematic reviews covering a range of topics and study designs. The Institute for Quality and Efficiency in Health Care (IQWiG) applied an objective approach, and external experts applied a conceptual approach for the same research questions. For each systematic review, the citations retrieved were combined and the overall pool of citations screened to determine sensitivity and precision. RESULTS: The objective approach yielded a weighted mean sensitivity and precision of 97% and 5%. The corresponding values for the conceptual approach were 75% and 4%. CONCLUSION: Our findings indicate that the objective approach applied by IQWiG for search strategy development yields higher sensitivity than and similar precision to a conceptual approach. The main advantage of the objective approach is that it produces consistent results across searches.", Humans; Information Storage and Retrieval/*methods/statistics & numerical data; MEDLINE/*statistics & numerical data; Prospective Studies; Reproducibility of Results; Research Design; *Review Literature as Topic; Sensitivity and Specificity; *Data mining; *Information storage and retrieval; *Medline; *Prospective studies; *Reproducibility of results; *Sensitivity and specificity,1,,,Search strategies,,
200,Kwak,2016,BMC bioinformatics,Automated prostate tissue referencing for cancer detection and diagnosis,"BACKGROUND: The current practice of histopathology review is limited in speed and accuracy. The current diagnostic paradigm does not fully describe the complex and complicated patterns of cancer. To address these needs, we develop an automated and objective system that facilitates a comprehensive and easy information management and decision-making. We also develop a tissue similarity measure scheme to broaden our understanding of tissue characteristics. RESULTS: The system includes a database of previously evaluated prostate tissue images, clinical information and a tissue retrieval process. In the system, a tissue is characterized by its morphology. The retrieval process seeks to find the closest matching cases with the tissue of interest. Moreover, we define 9 morphologic criteria by which a pathologist arrives at a histomorphologic diagnosis. Based on the 9 criteria, true tissue similarity is determined and serves as the gold standard of tissue retrieval. Here, we found a minimum of 4 and 3 matching cases, out of 5, for ~80 % and ~60 % of the queries when a match was defined as the tissue similarity score >/=5 and >/=6, respectively. We were also able to examine the relationship between tissues beyond the Gleason grading system due to the tissue similarity scoring system. CONCLUSIONS: Providing the closest matching cases and their clinical information with pathologists will help to conduct consistent and reliable diagnoses. Thus, we expect the system to facilitate quality maintenance and quality improvement of cancer pathology."," Automation; Databases, Factual; Humans; Male; Neoplasm Grading; Prostate/pathology; Prostatic Neoplasms/*diagnosis/*pathology; Reproducibility of Results; Database; Decision support; Infrared imaging; Prostate cancer; Tissue morphology; Tissue retrieval",-2,,,,,
